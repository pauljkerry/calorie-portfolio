## 目次
1. [コンペの参加の目的](#1-コンペ参加の目的)
2. [コンペの手法](#2-コンペの手法)
3. [コンペ全体を通しての気づきと学び](#3-コンペ全体を通しての気づきと学び)
4. [うまくいかなかったこと](#4-うまくいかなかったこと)
5. [今後の課題](#5-今後の課題)

## 1. コンペ参加の目的
- MLPの実装
- CatBoostでほかのGBDTモデルと遜色のない精度を出す
- アンサンブルでスコアを向上させる

## 2. コンペの手法
1. XGB, CB, MLP, RFR、Ridgeで予測値を作成する。また、LogRegでもXGBの残差をもとに予測値と真の値との残差をクラス分けして予測を行う。CVスコアは次の通り。  

| モデル | スコア   |評価指標|
|------|--------|----|
|XGB|0.05988|RMSLE|
|CB|0.05925|RMSLE|
|MLP|0.05986|RMSLE|
|RFR|0.06284|RMSLE|
|Ridge|0.171273|RMSLE|
|LogReg|1.01427|MLogLoss|

2. 1の予測値を異なるモデルに入力してスタッキングを行います。アンサンブルする際はXGBのみ100%データを使って学習した予測値を使います。

| モデル | 入力データ|CVスコア |重み|
|------|----|----|----|
|XGB|MLP 元データ|0.06012|16.6%|
|XGB|MLP LogReg|0.06024|45.7%|
|MLP|XGB CB|0.05938|19.9%|
|MLP|XGB CB RFR|0.05920|17.8%|

3. アンサンブル後のスコアは次のようになりました。

| CVスコア |パブリックスコア|プライベートスコア |
|------|----|----|
|0.05906|0.05703|0.05852|


## 3. コンペ全体を通しての気づきと学び

1. 前回参加したFertilizerのコンペではCustom Metricを設定してxgbやlgbを学習させていましたが、これを設定すると学習時間が大幅に増加することがわかりました。
2. 単体モデルではCatBoostが一番精度がよかったものの、他のモデルの予測値をもとに予測するとあまり精度が出ませんでした。これの仮説としては、予測値は元データと異なり、連続値で分布の幅が広いため、bin分割時に情報がつぶれてスコアが出なかったと考えました。
3. MLPはスコアが振動するため毎エポックごとに結果を観察したほうがよいと思いました。

## 4. うまくいかなかったこと
1. 特になし

## 5. 今後の課題
~~1. Notionではリレーション機能に制限があるためAirtableに移行する~~  
→ Airtableにすでに移行済み。今後は運用方法や拡張性の向上（API連携・自動化）に取り組む。    
2. 画像処理や自然言語処理に挑戦する