{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7636798d-02c3-4e61-b732-00317f9f9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import cudf\n",
    "import optuna\n",
    "import importlib\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import src.models.logreg.logreg_optuna_optimizer as op\n",
    "import src.models.logreg.logreg_cv_trainer as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a08409-763e-480d-ab9a-9844353171f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "env_path = Path.cwd().parent / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "url = os.environ.get(\"OPTUNA_STORAGE_URL\")\n",
    "\n",
    "# tr_df3 = cudf.read_csv(\"../artifacts/features/tr_df3.csv\")\n",
    "# test_df3 = cudf.read_csv(\"../artifacts/features/test_df3.csv\")\n",
    "# tr_df3_1 = cudf.read_csv(\"../artifacts/features/tr_df3_1.csv\")\n",
    "# test_df3_1 = cudf.read_csv(\"../artifacts/features/test_df3_1.csv\")\n",
    "# tr_df4 = cudf.read_csv(\"../artifacts/features/tr_df4.csv\")\n",
    "# test_df4 = cudf.read_csv(\"../artifacts/features/test_df4.csv\")\n",
    "# tr_df4_1 = cudf.read_csv(\"../artifacts/features/tr_df4_1.csv\")\n",
    "# test_df4_1 = cudf.read_csv(\"../artifacts/features/test_df4_1.csv\")\n",
    "tr_df5 = cudf.read_csv(\"../artifacts/features/tr_df5.csv\")\n",
    "test_df5 = cudf.read_csv(\"../artifacts/features/test_df5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff0cb43-615a-4f9f-be31-e3c9d1064b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-24 13:43:00,581] Using an existing study with name 'logreg_v6' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6f814173494df08e1ca707966eb769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.63281\n",
      "Valid Accuracy: 0.64131\n",
      "[I 2025-07-24 13:43:02,535] Trial 90 finished with value: 0.63281398467732 and parameters: {'C': 1.3715539208455454}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63277\n",
      "Valid Accuracy: 0.64187\n",
      "[I 2025-07-24 13:43:02,992] Trial 91 finished with value: 0.6327657158340763 and parameters: {'C': 1.0110411598085192}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63227\n",
      "Valid Accuracy: 0.64163\n",
      "[I 2025-07-24 13:43:03,392] Trial 92 finished with value: 0.6322679914273363 and parameters: {'C': 1.0579217228515136}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63348\n",
      "Valid Accuracy: 0.64059\n",
      "[I 2025-07-24 13:43:03,800] Trial 93 finished with value: 0.633476980319824 and parameters: {'C': 1.019535851961415}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63299\n",
      "Valid Accuracy: 0.64132\n",
      "[I 2025-07-24 13:43:04,263] Trial 94 finished with value: 0.6329946750324282 and parameters: {'C': 1.410395806052235}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63426\n",
      "Valid Accuracy: 0.63857\n",
      "[I 2025-07-24 13:43:04,785] Trial 95 finished with value: 0.6342633908177778 and parameters: {'C': 1.8184677927083748}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63357\n",
      "Valid Accuracy: 0.63955\n",
      "[I 2025-07-24 13:43:05,219] Trial 96 finished with value: 0.6335691516919201 and parameters: {'C': 0.805628548410603}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.63413\n",
      "Valid Accuracy: 0.63881\n",
      "[I 2025-07-24 13:43:08,860] Trial 97 finished with value: 0.6341349205411144 and parameters: {'C': 0.5765641462105032}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63417\n",
      "Valid Accuracy: 0.63955\n",
      "[I 2025-07-24 13:43:09,355] Trial 98 finished with value: 0.6341704494140472 and parameters: {'C': 0.9640141959390778}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63271\n",
      "Valid Accuracy: 0.64128\n",
      "[I 2025-07-24 13:43:09,792] Trial 99 finished with value: 0.6327085383375282 and parameters: {'C': 1.3124250278442053}. Best is trial 27 with value: 0.6320165003419045.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x76672a57a6e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tr_df4_1\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "objective = op.create_objective(tr_df4_1)\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=10,\n",
    "    study_name=\"logreg_v6\",\n",
    "    storage=url,\n",
    "    # sampler=random_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610ecb7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-24 14:45:33,515] Using an existing study with name 'logreg_v7' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93de2fb6e6b14683bbe555830e03b622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01401\n",
      "Valid Accuracy: 0.46717\n",
      "[I 2025-07-24 14:45:35,404] Trial 50 finished with value: 1.0140111686997448 and parameters: {'C': 3.867590150503501}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:04\n",
      "Valid Log Loss: 1.01494\n",
      "Valid Accuracy: 0.46722\n",
      "[I 2025-07-24 14:45:39,864] Trial 51 finished with value: 1.0149408497185304 and parameters: {'C': 4.484281885899878}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01537\n",
      "Valid Accuracy: 0.46563\n",
      "[I 2025-07-24 14:45:41,000] Trial 52 finished with value: 1.0153669063051838 and parameters: {'C': 1.7064822636193608}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01509\n",
      "Valid Accuracy: 0.46675\n",
      "[I 2025-07-24 14:45:42,233] Trial 53 finished with value: 1.0150872405067055 and parameters: {'C': 4.059912853205633}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01418\n",
      "Valid Accuracy: 0.46931\n",
      "[I 2025-07-24 14:45:43,376] Trial 54 finished with value: 1.0141762613435714 and parameters: {'C': 12.04948105609341}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01261\n",
      "Valid Accuracy: 0.47035\n",
      "[I 2025-07-24 14:45:44,522] Trial 55 finished with value: 1.0126067872423834 and parameters: {'C': 0.010275173174769787}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01451\n",
      "Valid Accuracy: 0.46925\n",
      "[I 2025-07-24 14:45:45,647] Trial 56 finished with value: 1.0145097707149868 and parameters: {'C': 0.02649148505551841}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01343\n",
      "Valid Accuracy: 0.46866\n",
      "[I 2025-07-24 14:45:46,785] Trial 57 finished with value: 1.0134309944273172 and parameters: {'C': 3.874819185694472}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01348\n",
      "Valid Accuracy: 0.46912\n",
      "[I 2025-07-24 14:45:47,921] Trial 58 finished with value: 1.0134783180129354 and parameters: {'C': 0.011126287436355058}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01399\n",
      "Valid Accuracy: 0.46904\n",
      "[I 2025-07-24 14:45:49,026] Trial 59 finished with value: 1.0139894123095925 and parameters: {'C': 0.011436336254524782}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01310\n",
      "Valid Accuracy: 0.46838\n",
      "[I 2025-07-24 14:45:50,199] Trial 60 finished with value: 1.013098298199372 and parameters: {'C': 0.011640371332106086}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01351\n",
      "Valid Accuracy: 0.46701\n",
      "[I 2025-07-24 14:45:51,370] Trial 61 finished with value: 1.0135107506524719 and parameters: {'C': 0.011153961517926962}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01391\n",
      "Valid Accuracy: 0.46861\n",
      "[I 2025-07-24 14:45:52,493] Trial 62 finished with value: 1.013905247748183 and parameters: {'C': 0.010945097797517825}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01364\n",
      "Valid Accuracy: 0.46838\n",
      "[I 2025-07-24 14:45:53,616] Trial 63 finished with value: 1.0136396265422016 and parameters: {'C': 0.024965573803399765}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01356\n",
      "Valid Accuracy: 0.46960\n",
      "[I 2025-07-24 14:45:54,811] Trial 64 finished with value: 1.0135580700792424 and parameters: {'C': 0.06849790714290094}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01411\n",
      "Valid Accuracy: 0.46794\n",
      "[I 2025-07-24 14:45:55,863] Trial 65 finished with value: 1.0141098289426485 and parameters: {'C': 0.06298091567501506}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01577\n",
      "Valid Accuracy: 0.46679\n",
      "[I 2025-07-24 14:45:56,949] Trial 66 finished with value: 1.0157730525538466 and parameters: {'C': 0.08573366119928742}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01523\n",
      "Valid Accuracy: 0.46661\n",
      "[I 2025-07-24 14:45:58,032] Trial 67 finished with value: 1.0152311167430672 and parameters: {'C': 0.025200407607721034}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01517\n",
      "Valid Accuracy: 0.46711\n",
      "[I 2025-07-24 14:45:59,176] Trial 68 finished with value: 1.0151743770882975 and parameters: {'C': 0.01261877954413446}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01549\n",
      "Valid Accuracy: 0.46567\n",
      "[I 2025-07-24 14:46:00,315] Trial 69 finished with value: 1.0154875116642046 and parameters: {'C': 0.015060219158784442}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01391\n",
      "Valid Accuracy: 0.46918\n",
      "[I 2025-07-24 14:46:01,555] Trial 70 finished with value: 1.0139148488671017 and parameters: {'C': 0.021296700902325483}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01486\n",
      "Valid Accuracy: 0.46729\n",
      "[I 2025-07-24 14:46:02,658] Trial 71 finished with value: 1.0148623044169816 and parameters: {'C': 0.027577869787803203}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01537\n",
      "Valid Accuracy: 0.46460\n",
      "[I 2025-07-24 14:46:03,780] Trial 72 finished with value: 1.0153711654949682 and parameters: {'C': 0.0205725969214237}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01473\n",
      "Valid Accuracy: 0.46727\n",
      "[I 2025-07-24 14:46:04,821] Trial 73 finished with value: 1.014732086956777 and parameters: {'C': 0.010515859563107681}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01320\n",
      "Valid Accuracy: 0.46765\n",
      "[I 2025-07-24 14:46:05,973] Trial 74 finished with value: 1.0131997198041467 and parameters: {'C': 0.030062685850990003}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01521\n",
      "Valid Accuracy: 0.46615\n",
      "[I 2025-07-24 14:46:07,101] Trial 75 finished with value: 1.0152052781669754 and parameters: {'C': 0.013768515932170983}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01360\n",
      "Valid Accuracy: 0.46917\n",
      "[I 2025-07-24 14:46:08,239] Trial 76 finished with value: 1.0135990848390835 and parameters: {'C': 0.05761525691867791}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:04\n",
      "Valid Log Loss: 1.01334\n",
      "Valid Accuracy: 0.47035\n",
      "[I 2025-07-24 14:46:12,599] Trial 77 finished with value: 1.0133443725323965 and parameters: {'C': 0.03339576026499911}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01384\n",
      "Valid Accuracy: 0.46805\n",
      "[I 2025-07-24 14:46:13,735] Trial 78 finished with value: 1.0138352590845936 and parameters: {'C': 0.031563635149597695}. Best is trial 55 with value: 1.0126067872423834.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 1.01307\n",
      "Valid Accuracy: 0.46860\n",
      "[I 2025-07-24 14:46:14,839] Trial 79 finished with value: 1.0130717405836303 and parameters: {'C': 0.018632246669321187}. Best is trial 55 with value: 1.0126067872423834.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x7c2a69fadc30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tr_df5\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "objective = op.create_objective(tr_df5)\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=30,\n",
    "    study_name=\"logreg_v7\",\n",
    "    storage=url,\n",
    "    # sampler=random_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee546e32-2aaf-4d1c-8d34-715c57ebb288",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 01:06:35,067] A new study created in RDB with name: logreg_v4.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f1d37c1b224991971db8a505e5f8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21170\n",
      "Valid Accuracy: 0.93980\n",
      "[I 2025-07-20 01:06:38,053] Trial 0 finished with value: 0.2117047464496658 and parameters: {'C': 93.3570709550824}. Best is trial 0 with value: 0.2117047464496658.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21094\n",
      "Valid Accuracy: 0.93998\n",
      "[I 2025-07-20 01:06:39,376] Trial 1 finished with value: 0.2109363433988954 and parameters: {'C': 0.11391337268914487}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.21216\n",
      "Valid Accuracy: 0.93977\n",
      "[I 2025-07-20 01:06:41,932] Trial 2 finished with value: 0.21215648159960723 and parameters: {'C': 0.0666604296958828}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21192\n",
      "Valid Accuracy: 0.93976\n",
      "[I 2025-07-20 01:06:43,444] Trial 3 finished with value: 0.21191537095333002 and parameters: {'C': 9.263752012793217}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.21147\n",
      "Valid Accuracy: 0.93998\n",
      "[I 2025-07-20 01:06:45,870] Trial 4 finished with value: 0.2114669420374136 and parameters: {'C': 0.03096140171948966}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21178\n",
      "Valid Accuracy: 0.93985\n",
      "[I 2025-07-20 01:06:47,264] Trial 5 finished with value: 0.21178303427027523 and parameters: {'C': 83.45105169850352}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21153\n",
      "Valid Accuracy: 0.93963\n",
      "[I 2025-07-20 01:06:49,316] Trial 6 finished with value: 0.21153090753456957 and parameters: {'C': 0.01309128278661112}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.21108\n",
      "Valid Accuracy: 0.93985\n",
      "[I 2025-07-20 01:06:51,955] Trial 7 finished with value: 0.211077202008799 and parameters: {'C': 0.10956279906730933}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21188\n",
      "Valid Accuracy: 0.93978\n",
      "[I 2025-07-20 01:06:53,372] Trial 8 finished with value: 0.2118825013099199 and parameters: {'C': 17.25296520646538}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.21057\n",
      "Valid Accuracy: 0.93989\n",
      "[I 2025-07-20 01:06:55,730] Trial 9 finished with value: 0.21057143658950117 and parameters: {'C': 0.0732184010963745}. Best is trial 9 with value: 0.21057143658950117.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x711d18b56a70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tr_df3_1\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "objective = op.create_objective(tr_df3_1)\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=10,\n",
    "    study_name=\"logreg_v4.1\",\n",
    "    storage=url,\n",
    "    # sampler=random_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110d1944-bca6-47c7-9f7a-4e61eee55422",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-19 01:54:32,641] Using an existing study with name 'logreg_v3' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9320db02dd99459fb6375d800f45f954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:17:41\n",
      "Valid Log Loss: 0.20910\n",
      "Valid Accuracy: 0.93943\n",
      "[I 2025-07-19 02:12:15,742] Trial 2 finished with value: 0.20910350751242435 and parameters: {'C': 1.8848175879481617, 'penalty': 'l2'}. Best is trial 0 with value: 0.20901691660591315.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:21:38\n",
      "Valid Log Loss: 0.20901\n",
      "Valid Accuracy: 0.93949\n",
      "[I 2025-07-19 02:33:55,515] Trial 3 finished with value: 0.20901296233246905 and parameters: {'C': 6.258843509756425, 'penalty': 'l2'}. Best is trial 3 with value: 0.20901296233246905.\n",
      "Training time: 00:16:55\n",
      "Valid Log Loss: 0.20912\n",
      "Valid Accuracy: 0.93945\n",
      "[I 2025-07-19 02:50:51,761] Trial 4 finished with value: 0.20912404428086206 and parameters: {'C': 1.6203221427601968, 'penalty': 'l2'}. Best is trial 3 with value: 0.20901296233246905.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:21:36\n",
      "Valid Log Loss: 0.20901\n",
      "Valid Accuracy: 0.93949\n",
      "[I 2025-07-19 03:12:29,512] Trial 5 finished with value: 0.20900832085435486 and parameters: {'C': 7.272605409622588, 'penalty': 'l2'}. Best is trial 5 with value: 0.20900832085435486.\n",
      "Training time: 00:20:39\n",
      "Valid Log Loss: 0.20905\n",
      "Valid Accuracy: 0.93947\n",
      "[I 2025-07-19 03:33:10,094] Trial 6 finished with value: 0.20904716078532107 and parameters: {'C': 3.2634088459295207, 'penalty': 'l2'}. Best is trial 5 with value: 0.20900832085435486.\n",
      "[W 2025-07-19 03:36:25,616] Trial 7 failed with parameters: {'C': 4.058497136802884, 'penalty': 'l2'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\hanse\\kaggle\\calorie\\src\\models\\logreg\\logreg_optuna_optimizer.py\", line 42, in objective\n",
      "    trainer.fit_one_fold(tr_df, fold=0)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hanse\\kaggle\\calorie\\src\\models\\logreg\\logreg_cv_trainer.py\", line 196, in fit_one_fold\n",
      "    pred_labels = model.predict(X_val)\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1350, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "        path_func(\n",
      "    ...<20 lines>...\n",
      "        for class_, warm_start_coef_ in zip(classes_, warm_start_coef)\n",
      "    )\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ~~~~^^^^^^^^\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1762, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-19 03:36:25,632] Trial 7 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m objective \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mcreate_objective(\n\u001b[0;32m      5\u001b[0m     tr_df4,\n\u001b[0;32m      6\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m random_sampler \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mRandomSampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m op\u001b[38;5;241m.\u001b[39mrun_optuna_search(\n\u001b[0;32m     12\u001b[0m     objective,\n\u001b[0;32m     13\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m     14\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     15\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogreg_v3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     storage\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# sampler=random_sampler\u001b[39;00m\n\u001b[0;32m     18\u001b[0m )\n",
      "File \u001b[1;32m~\\kaggle\\calorie\\src\\models\\logreg\\logreg_optuna_optimizer.py:88\u001b[0m, in \u001b[0;36mrun_optuna_search\u001b[1;34m(objective, n_trials, n_jobs, study_name, storage, initial_params, sampler)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     study\u001b[38;5;241m.\u001b[39menqueue_trial(initial_params)\n\u001b[1;32m---> 88\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[0;32m     89\u001b[0m     objective,\n\u001b[0;32m     90\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m     91\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m     92\u001b[0m     show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     93\u001b[0m )\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    389\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m     _optimize(\n\u001b[0;32m    490\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    491\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    492\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    493\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    494\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    495\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    496\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    497\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    498\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    499\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m         _optimize_sequential(\n\u001b[0;32m     65\u001b[0m             study,\n\u001b[0;32m     66\u001b[0m             func,\n\u001b[0;32m     67\u001b[0m             n_trials,\n\u001b[0;32m     68\u001b[0m             timeout,\n\u001b[0;32m     69\u001b[0m             catch,\n\u001b[0;32m     70\u001b[0m             callbacks,\n\u001b[0;32m     71\u001b[0m             gc_after_trial,\n\u001b[0;32m     72\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     73\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     74\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     75\u001b[0m         )\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    249\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    252\u001b[0m ):\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[1;32m~\\kaggle\\calorie\\src\\models\\logreg\\logreg_optuna_optimizer.py:42\u001b[0m, in \u001b[0;36mcreate_objective.<locals>.objective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     28\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e2\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m     36\u001b[0m }\n\u001b[0;32m     38\u001b[0m trainer \u001b[38;5;241m=\u001b[39m LogRegCVTrainer(\n\u001b[0;32m     39\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams, n_splits\u001b[38;5;241m=\u001b[39mn_splits\n\u001b[0;32m     40\u001b[0m )\n\u001b[1;32m---> 42\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit_one_fold(tr_df, fold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mfold_scores[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\kaggle\\calorie\\src\\models\\logreg\\logreg_cv_trainer.py:196\u001b[0m, in \u001b[0;36mfit_one_fold\u001b[1;34m(self, tr_df, fold, sample_weights)\u001b[0m\n\u001b[0;32m    193\u001b[0m print_duration(start, end)\n\u001b[0;32m    195\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)\n\u001b[1;32m--> 196\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m    197\u001b[0m logloss \u001b[38;5;241m=\u001b[39m log_loss(y_val, preds)\n\u001b[0;32m    198\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_val, pred_labels)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1350\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1350\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39mprefer)(\n\u001b[0;32m   1351\u001b[0m     path_func(\n\u001b[0;32m   1352\u001b[0m         X,\n\u001b[0;32m   1353\u001b[0m         y,\n\u001b[0;32m   1354\u001b[0m         pos_class\u001b[38;5;241m=\u001b[39mclass_,\n\u001b[0;32m   1355\u001b[0m         Cs\u001b[38;5;241m=\u001b[39m[C_],\n\u001b[0;32m   1356\u001b[0m         l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[0;32m   1357\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[0;32m   1358\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m   1359\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   1360\u001b[0m         solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[0;32m   1361\u001b[0m         multi_class\u001b[38;5;241m=\u001b[39mmulti_class,\n\u001b[0;32m   1362\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m   1363\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m   1364\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1365\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m   1366\u001b[0m         coef\u001b[38;5;241m=\u001b[39mwarm_start_coef_,\n\u001b[0;32m   1367\u001b[0m         penalty\u001b[38;5;241m=\u001b[39mpenalty,\n\u001b[0;32m   1368\u001b[0m         max_squared_sum\u001b[38;5;241m=\u001b[39mmax_squared_sum,\n\u001b[0;32m   1369\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1370\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m   1371\u001b[0m     )\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_, warm_start_coef_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classes_, warm_start_coef)\n\u001b[0;32m   1373\u001b[0m )\n\u001b[0;32m   1375\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tr_df4\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "objective = op.create_objective(tr_df4)\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=30,\n",
    "    study_name=\"logreg_v3\",\n",
    "    storage=url,\n",
    "    # sampler=random_sampler\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.12",
   "language": "python",
   "name": "rapids-23.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
