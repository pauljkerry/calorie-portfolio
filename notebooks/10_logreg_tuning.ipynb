{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7636798d-02c3-4e61-b732-00317f9f9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import cudf\n",
    "import optuna\n",
    "import importlib\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import src.models.logreg.logreg_optuna_optimizer as op\n",
    "import src.models.logreg.logreg_cv_trainer as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a08409-763e-480d-ab9a-9844353171f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "env_path = Path.cwd().parent / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "url = os.environ.get(\"OPTUNA_STORAGE_URL\")\n",
    "\n",
    "# tr_df3 = cudf.read_csv(\"../artifacts/features/tr_df3.csv\")\n",
    "# test_df3 = cudf.read_csv(\"../artifacts/features/test_df3.csv\")\n",
    "# tr_df3_1 = cudf.read_csv(\"../artifacts/features/tr_df3_1.csv\")\n",
    "# test_df3_1 = cudf.read_csv(\"../artifacts/features/test_df3_1.csv\")\n",
    "# tr_df4 = cudf.read_csv(\"../artifacts/features/tr_df4.csv\")\n",
    "# test_df4 = cudf.read_csv(\"../artifacts/features/test_df4.csv\")\n",
    "# tr_df4_1 = cudf.read_csv(\"../artifacts/features/tr_df4_1.csv\")\n",
    "# test_df4_1 = cudf.read_csv(\"../artifacts/features/test_df4_1.csv\")\n",
    "tr_df5 = cudf.read_csv(\"../artifacts/features/tr_df5.csv\")\n",
    "test_df5 = cudf.read_csv(\"../artifacts/features/test_df5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff0cb43-615a-4f9f-be31-e3c9d1064b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 01:57:27,939] Using an existing study with name 'logreg_v7' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88a3a9533cc4460b6ca7f9146e34068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01553\n",
      "Valid Accuracy: 0.46731\n",
      "[I 2025-07-20 01:57:29,383] Trial 10 finished with value: 1.0155330302940428 and parameters: {'C': 0.31489116479568624}. Best is trial 10 with value: 1.0155330302940428.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01689\n",
      "Valid Accuracy: 0.46591\n",
      "[I 2025-07-20 01:57:30,746] Trial 11 finished with value: 1.0168942321356234 and parameters: {'C': 63.512210106407046}. Best is trial 10 with value: 1.0155330302940428.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01794\n",
      "Valid Accuracy: 0.46576\n",
      "[I 2025-07-20 01:57:32,133] Trial 12 finished with value: 1.0179437711704726 and parameters: {'C': 8.471801418819979}. Best is trial 10 with value: 1.0155330302940428.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01848\n",
      "Valid Accuracy: 0.46490\n",
      "[I 2025-07-20 01:57:33,605] Trial 13 finished with value: 1.0184841783726943 and parameters: {'C': 2.481040974867813}. Best is trial 10 with value: 1.0155330302940428.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01730\n",
      "Valid Accuracy: 0.46420\n",
      "[I 2025-07-20 01:57:35,020] Trial 14 finished with value: 1.0173047458075157 and parameters: {'C': 0.04207988669606638}. Best is trial 10 with value: 1.0155330302940428.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01623\n",
      "Valid Accuracy: 0.46630\n",
      "[I 2025-07-20 01:57:36,390] Trial 15 finished with value: 1.0162253093945706 and parameters: {'C': 0.042070539502879395}. Best is trial 10 with value: 1.0155330302940428.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01595\n",
      "Valid Accuracy: 0.46796\n",
      "[I 2025-07-20 01:57:37,885] Trial 16 finished with value: 1.0159486039303907 and parameters: {'C': 0.017073967431528128}. Best is trial 10 with value: 1.0155330302940428.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 1.01800\n",
      "Valid Accuracy: 0.46641\n",
      "[I 2025-07-20 01:57:40,540] Trial 17 finished with value: 1.0180037913158921 and parameters: {'C': 29.154431891537552}. Best is trial 10 with value: 1.0155330302940428.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01724\n",
      "Valid Accuracy: 0.46691\n",
      "[I 2025-07-20 01:57:41,811] Trial 18 finished with value: 1.0172385002757647 and parameters: {'C': 2.5378155082656657}. Best is trial 10 with value: 1.0155330302940428.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01826\n",
      "Valid Accuracy: 0.46523\n",
      "[I 2025-07-20 01:57:43,198] Trial 19 finished with value: 1.0182635197738925 and parameters: {'C': 6.79657809075816}. Best is trial 10 with value: 1.0155330302940428.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x796b9ef29e70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tr_df5\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "objective = op.create_objective(tr_df5)\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=10,\n",
    "    study_name=\"logreg_v7\",\n",
    "    storage=url,\n",
    "    sampler=random_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610ecb7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 01:40:49,160] Using an existing study with name 'logreg_v6' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2142015ff2344c449a1c9e28c2514f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.63552\n",
      "Valid Accuracy: 0.63984\n",
      "[I 2025-07-20 01:40:51,226] Trial 10 finished with value: 0.6355169286919478 and parameters: {'C': 0.31489116479568624}. Best is trial 9 with value: 0.6342037411441728.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63561\n",
      "Valid Accuracy: 0.63831\n",
      "[I 2025-07-20 01:40:51,674] Trial 11 finished with value: 0.6356097780820297 and parameters: {'C': 63.512210106407046}. Best is trial 9 with value: 0.6342037411441728.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63593\n",
      "Valid Accuracy: 0.63957\n",
      "[I 2025-07-20 01:40:52,165] Trial 12 finished with value: 0.635927170687221 and parameters: {'C': 8.471801418819979}. Best is trial 9 with value: 0.6342037411441728.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63507\n",
      "Valid Accuracy: 0.63991\n",
      "[I 2025-07-20 01:40:52,644] Trial 13 finished with value: 0.6350687393487052 and parameters: {'C': 2.481040974867813}. Best is trial 9 with value: 0.6342037411441728.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63608\n",
      "Valid Accuracy: 0.63841\n",
      "[I 2025-07-20 01:40:53,102] Trial 14 finished with value: 0.6360841800279 and parameters: {'C': 0.04207988669606638}. Best is trial 9 with value: 0.6342037411441728.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63569\n",
      "Valid Accuracy: 0.63886\n",
      "[I 2025-07-20 01:40:53,536] Trial 15 finished with value: 0.635691545675753 and parameters: {'C': 0.042070539502879395}. Best is trial 9 with value: 0.6342037411441728.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63655\n",
      "Valid Accuracy: 0.63843\n",
      "[I 2025-07-20 01:40:53,985] Trial 16 finished with value: 0.6365468865308385 and parameters: {'C': 0.017073967431528128}. Best is trial 9 with value: 0.6342037411441728.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63535\n",
      "Valid Accuracy: 0.64022\n",
      "[I 2025-07-20 01:40:54,454] Trial 17 finished with value: 0.6353488629554256 and parameters: {'C': 29.154431891537552}. Best is trial 9 with value: 0.6342037411441728.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63610\n",
      "Valid Accuracy: 0.63839\n",
      "[I 2025-07-20 01:40:54,897] Trial 18 finished with value: 0.63610423719812 and parameters: {'C': 2.5378155082656657}. Best is trial 9 with value: 0.6342037411441728.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63504\n",
      "Valid Accuracy: 0.64051\n",
      "[I 2025-07-20 01:40:55,336] Trial 19 finished with value: 0.6350413611213748 and parameters: {'C': 6.79657809075816}. Best is trial 9 with value: 0.6342037411441728.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x796ba0d6c850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tr_df4_1\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "objective = op.create_objective(tr_df4_1)\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=10,\n",
    "    study_name=\"logreg_v6\",\n",
    "    storage=url,\n",
    "    sampler=random_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee546e32-2aaf-4d1c-8d34-715c57ebb288",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 01:06:35,067] A new study created in RDB with name: logreg_v4.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f1d37c1b224991971db8a505e5f8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21170\n",
      "Valid Accuracy: 0.93980\n",
      "[I 2025-07-20 01:06:38,053] Trial 0 finished with value: 0.2117047464496658 and parameters: {'C': 93.3570709550824}. Best is trial 0 with value: 0.2117047464496658.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21094\n",
      "Valid Accuracy: 0.93998\n",
      "[I 2025-07-20 01:06:39,376] Trial 1 finished with value: 0.2109363433988954 and parameters: {'C': 0.11391337268914487}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.21216\n",
      "Valid Accuracy: 0.93977\n",
      "[I 2025-07-20 01:06:41,932] Trial 2 finished with value: 0.21215648159960723 and parameters: {'C': 0.0666604296958828}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21192\n",
      "Valid Accuracy: 0.93976\n",
      "[I 2025-07-20 01:06:43,444] Trial 3 finished with value: 0.21191537095333002 and parameters: {'C': 9.263752012793217}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.21147\n",
      "Valid Accuracy: 0.93998\n",
      "[I 2025-07-20 01:06:45,870] Trial 4 finished with value: 0.2114669420374136 and parameters: {'C': 0.03096140171948966}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21178\n",
      "Valid Accuracy: 0.93985\n",
      "[I 2025-07-20 01:06:47,264] Trial 5 finished with value: 0.21178303427027523 and parameters: {'C': 83.45105169850352}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21153\n",
      "Valid Accuracy: 0.93963\n",
      "[I 2025-07-20 01:06:49,316] Trial 6 finished with value: 0.21153090753456957 and parameters: {'C': 0.01309128278661112}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.21108\n",
      "Valid Accuracy: 0.93985\n",
      "[I 2025-07-20 01:06:51,955] Trial 7 finished with value: 0.211077202008799 and parameters: {'C': 0.10956279906730933}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21188\n",
      "Valid Accuracy: 0.93978\n",
      "[I 2025-07-20 01:06:53,372] Trial 8 finished with value: 0.2118825013099199 and parameters: {'C': 17.25296520646538}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.21057\n",
      "Valid Accuracy: 0.93989\n",
      "[I 2025-07-20 01:06:55,730] Trial 9 finished with value: 0.21057143658950117 and parameters: {'C': 0.0732184010963745}. Best is trial 9 with value: 0.21057143658950117.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x711d18b56a70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tr_df3_1\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "objective = op.create_objective(tr_df3_1)\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=10,\n",
    "    study_name=\"logreg_v4.1\",\n",
    "    storage=url,\n",
    "    # sampler=random_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110d1944-bca6-47c7-9f7a-4e61eee55422",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-19 01:54:32,641] Using an existing study with name 'logreg_v3' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9320db02dd99459fb6375d800f45f954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:17:41\n",
      "Valid Log Loss: 0.20910\n",
      "Valid Accuracy: 0.93943\n",
      "[I 2025-07-19 02:12:15,742] Trial 2 finished with value: 0.20910350751242435 and parameters: {'C': 1.8848175879481617, 'penalty': 'l2'}. Best is trial 0 with value: 0.20901691660591315.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:21:38\n",
      "Valid Log Loss: 0.20901\n",
      "Valid Accuracy: 0.93949\n",
      "[I 2025-07-19 02:33:55,515] Trial 3 finished with value: 0.20901296233246905 and parameters: {'C': 6.258843509756425, 'penalty': 'l2'}. Best is trial 3 with value: 0.20901296233246905.\n",
      "Training time: 00:16:55\n",
      "Valid Log Loss: 0.20912\n",
      "Valid Accuracy: 0.93945\n",
      "[I 2025-07-19 02:50:51,761] Trial 4 finished with value: 0.20912404428086206 and parameters: {'C': 1.6203221427601968, 'penalty': 'l2'}. Best is trial 3 with value: 0.20901296233246905.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:21:36\n",
      "Valid Log Loss: 0.20901\n",
      "Valid Accuracy: 0.93949\n",
      "[I 2025-07-19 03:12:29,512] Trial 5 finished with value: 0.20900832085435486 and parameters: {'C': 7.272605409622588, 'penalty': 'l2'}. Best is trial 5 with value: 0.20900832085435486.\n",
      "Training time: 00:20:39\n",
      "Valid Log Loss: 0.20905\n",
      "Valid Accuracy: 0.93947\n",
      "[I 2025-07-19 03:33:10,094] Trial 6 finished with value: 0.20904716078532107 and parameters: {'C': 3.2634088459295207, 'penalty': 'l2'}. Best is trial 5 with value: 0.20900832085435486.\n",
      "[W 2025-07-19 03:36:25,616] Trial 7 failed with parameters: {'C': 4.058497136802884, 'penalty': 'l2'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\hanse\\kaggle\\calorie\\src\\models\\logreg\\logreg_optuna_optimizer.py\", line 42, in objective\n",
      "    trainer.fit_one_fold(tr_df, fold=0)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hanse\\kaggle\\calorie\\src\\models\\logreg\\logreg_cv_trainer.py\", line 196, in fit_one_fold\n",
      "    pred_labels = model.predict(X_val)\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1350, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "        path_func(\n",
      "    ...<20 lines>...\n",
      "        for class_, warm_start_coef_ in zip(classes_, warm_start_coef)\n",
      "    )\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ~~~~^^^^^^^^\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1762, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-19 03:36:25,632] Trial 7 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m objective \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mcreate_objective(\n\u001b[0;32m      5\u001b[0m     tr_df4,\n\u001b[0;32m      6\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m random_sampler \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mRandomSampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m op\u001b[38;5;241m.\u001b[39mrun_optuna_search(\n\u001b[0;32m     12\u001b[0m     objective,\n\u001b[0;32m     13\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m     14\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     15\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogreg_v3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     storage\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# sampler=random_sampler\u001b[39;00m\n\u001b[0;32m     18\u001b[0m )\n",
      "File \u001b[1;32m~\\kaggle\\calorie\\src\\models\\logreg\\logreg_optuna_optimizer.py:88\u001b[0m, in \u001b[0;36mrun_optuna_search\u001b[1;34m(objective, n_trials, n_jobs, study_name, storage, initial_params, sampler)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     study\u001b[38;5;241m.\u001b[39menqueue_trial(initial_params)\n\u001b[1;32m---> 88\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[0;32m     89\u001b[0m     objective,\n\u001b[0;32m     90\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m     91\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m     92\u001b[0m     show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     93\u001b[0m )\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    389\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m     _optimize(\n\u001b[0;32m    490\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    491\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    492\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    493\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    494\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    495\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    496\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    497\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    498\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    499\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m         _optimize_sequential(\n\u001b[0;32m     65\u001b[0m             study,\n\u001b[0;32m     66\u001b[0m             func,\n\u001b[0;32m     67\u001b[0m             n_trials,\n\u001b[0;32m     68\u001b[0m             timeout,\n\u001b[0;32m     69\u001b[0m             catch,\n\u001b[0;32m     70\u001b[0m             callbacks,\n\u001b[0;32m     71\u001b[0m             gc_after_trial,\n\u001b[0;32m     72\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     73\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     74\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     75\u001b[0m         )\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    249\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    252\u001b[0m ):\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[1;32m~\\kaggle\\calorie\\src\\models\\logreg\\logreg_optuna_optimizer.py:42\u001b[0m, in \u001b[0;36mcreate_objective.<locals>.objective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     28\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e2\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m     36\u001b[0m }\n\u001b[0;32m     38\u001b[0m trainer \u001b[38;5;241m=\u001b[39m LogRegCVTrainer(\n\u001b[0;32m     39\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams, n_splits\u001b[38;5;241m=\u001b[39mn_splits\n\u001b[0;32m     40\u001b[0m )\n\u001b[1;32m---> 42\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit_one_fold(tr_df, fold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mfold_scores[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\kaggle\\calorie\\src\\models\\logreg\\logreg_cv_trainer.py:196\u001b[0m, in \u001b[0;36mfit_one_fold\u001b[1;34m(self, tr_df, fold, sample_weights)\u001b[0m\n\u001b[0;32m    193\u001b[0m print_duration(start, end)\n\u001b[0;32m    195\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)\n\u001b[1;32m--> 196\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m    197\u001b[0m logloss \u001b[38;5;241m=\u001b[39m log_loss(y_val, preds)\n\u001b[0;32m    198\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_val, pred_labels)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1350\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1350\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39mprefer)(\n\u001b[0;32m   1351\u001b[0m     path_func(\n\u001b[0;32m   1352\u001b[0m         X,\n\u001b[0;32m   1353\u001b[0m         y,\n\u001b[0;32m   1354\u001b[0m         pos_class\u001b[38;5;241m=\u001b[39mclass_,\n\u001b[0;32m   1355\u001b[0m         Cs\u001b[38;5;241m=\u001b[39m[C_],\n\u001b[0;32m   1356\u001b[0m         l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[0;32m   1357\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[0;32m   1358\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m   1359\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   1360\u001b[0m         solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[0;32m   1361\u001b[0m         multi_class\u001b[38;5;241m=\u001b[39mmulti_class,\n\u001b[0;32m   1362\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m   1363\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m   1364\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1365\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m   1366\u001b[0m         coef\u001b[38;5;241m=\u001b[39mwarm_start_coef_,\n\u001b[0;32m   1367\u001b[0m         penalty\u001b[38;5;241m=\u001b[39mpenalty,\n\u001b[0;32m   1368\u001b[0m         max_squared_sum\u001b[38;5;241m=\u001b[39mmax_squared_sum,\n\u001b[0;32m   1369\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1370\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m   1371\u001b[0m     )\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_, warm_start_coef_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classes_, warm_start_coef)\n\u001b[0;32m   1373\u001b[0m )\n\u001b[0;32m   1375\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tr_df4\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "objective = op.create_objective(tr_df4)\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=30,\n",
    "    study_name=\"logreg_v3\",\n",
    "    storage=url,\n",
    "    # sampler=random_sampler\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RAPIDS)",
   "language": "python",
   "name": "rapids-23.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
