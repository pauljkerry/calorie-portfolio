{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7636798d-02c3-4e61-b732-00317f9f9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import cudf\n",
    "import optuna\n",
    "import importlib\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import src.models.logreg.logreg_optuna_optimizer as op\n",
    "import src.models.logreg.logreg_cv_trainer as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a08409-763e-480d-ab9a-9844353171f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "env_path = Path.cwd().parent / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "url = os.environ.get(\"OPTUNA_STORAGE_URL\")\n",
    "\n",
    "# tr_df3 = cudf.read_csv(\"../artifacts/features/tr_df3.csv\")\n",
    "# test_df3 = cudf.read_csv(\"../artifacts/features/test_df3.csv\")\n",
    "# tr_df3_1 = cudf.read_csv(\"../artifacts/features/tr_df3_1.csv\")\n",
    "# test_df3_1 = cudf.read_csv(\"../artifacts/features/test_df3_1.csv\")\n",
    "# tr_df4 = cudf.read_csv(\"../artifacts/features/tr_df4.csv\")\n",
    "# test_df4 = cudf.read_csv(\"../artifacts/features/test_df4.csv\")\n",
    "tr_df4_1 = cudf.read_csv(\"../artifacts/features/tr_df4_1.csv\")\n",
    "test_df4_1 = cudf.read_csv(\"../artifacts/features/test_df4_1.csv\")\n",
    "tr_df5 = cudf.read_csv(\"../artifacts/features/tr_df5.csv\")\n",
    "test_df5 = cudf.read_csv(\"../artifacts/features/test_df5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff0cb43-615a-4f9f-be31-e3c9d1064b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 19:37:31,170] Using an existing study with name 'logreg_v7' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e581645e424b66812a2d4af3ed179a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01409\n",
      "Valid Accuracy: 0.46799\n",
      "[I 2025-07-20 19:37:33,601] Trial 40 finished with value: 1.0140949030779125 and parameters: {'C': 0.6746571561231897}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:03\n",
      "Valid Log Loss: 1.01626\n",
      "Valid Accuracy: 0.46417\n",
      "[I 2025-07-20 19:37:36,905] Trial 41 finished with value: 1.0162647313494173 and parameters: {'C': 0.6890696159364506}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:03\n",
      "Valid Log Loss: 1.01479\n",
      "Valid Accuracy: 0.46721\n",
      "[I 2025-07-20 19:37:40,280] Trial 42 finished with value: 1.0147864799584088 and parameters: {'C': 0.7808139021567879}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01449\n",
      "Valid Accuracy: 0.46831\n",
      "[I 2025-07-20 19:37:42,001] Trial 43 finished with value: 1.0144871655296346 and parameters: {'C': 1.4023864454475932}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:03\n",
      "Valid Log Loss: 1.01474\n",
      "Valid Accuracy: 0.46699\n",
      "[I 2025-07-20 19:37:45,483] Trial 44 finished with value: 1.014737279213197 and parameters: {'C': 15.312768317502842}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:03\n",
      "Valid Log Loss: 1.01575\n",
      "Valid Accuracy: 0.46733\n",
      "[I 2025-07-20 19:37:48,896] Trial 45 finished with value: 1.0157517792088027 and parameters: {'C': 0.19067392206911776}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 1.01575\n",
      "Valid Accuracy: 0.46507\n",
      "[I 2025-07-20 19:37:50,799] Trial 46 finished with value: 1.0157543549050914 and parameters: {'C': 4.105878164386948}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:03\n",
      "Valid Log Loss: 1.01423\n",
      "Valid Accuracy: 0.46691\n",
      "[I 2025-07-20 19:37:54,187] Trial 47 finished with value: 1.0142277209918154 and parameters: {'C': 1.2875850511483868}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:03\n",
      "Valid Log Loss: 1.01484\n",
      "Valid Accuracy: 0.46580\n",
      "[I 2025-07-20 19:37:57,590] Trial 48 finished with value: 1.0148378226515566 and parameters: {'C': 0.1479090411428502}. Best is trial 23 with value: 1.0135289687700821.\n",
      "Training time: 00:00:05\n",
      "Valid Log Loss: 1.01474\n",
      "Valid Accuracy: 0.46649\n",
      "[I 2025-07-20 19:38:03,355] Trial 49 finished with value: 1.0147400269624993 and parameters: {'C': 13.905697014402438}. Best is trial 23 with value: 1.0135289687700821.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x7723f64ae3e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tr_df5\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "objective = op.create_objective(tr_df5)\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=10,\n",
    "    study_name=\"logreg_v7\",\n",
    "    storage=url,\n",
    "    # sampler=random_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610ecb7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 19:13:17,620] Using an existing study with name 'logreg_v6' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa507155846f4be6be8b8e9379bbd6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63370\n",
      "Valid Accuracy: 0.64017\n",
      "[I 2025-07-20 19:13:18,318] Trial 60 finished with value: 0.633700765066514 and parameters: {'C': 13.422546229945732}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63346\n",
      "Valid Accuracy: 0.64104\n",
      "[I 2025-07-20 19:13:18,771] Trial 61 finished with value: 0.6334560942802101 and parameters: {'C': 42.193476490256685}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63334\n",
      "Valid Accuracy: 0.64187\n",
      "[I 2025-07-20 19:13:19,224] Trial 62 finished with value: 0.6333391121521558 and parameters: {'C': 99.43963598631777}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63508\n",
      "Valid Accuracy: 0.63894\n",
      "[I 2025-07-20 19:13:19,719] Trial 63 finished with value: 0.6350797517797363 and parameters: {'C': 4.197503350944385}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63352\n",
      "Valid Accuracy: 0.64103\n",
      "[I 2025-07-20 19:13:20,237] Trial 64 finished with value: 0.6335160689464568 and parameters: {'C': 18.1189853805934}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63383\n",
      "Valid Accuracy: 0.64101\n",
      "[I 2025-07-20 19:13:20,703] Trial 65 finished with value: 0.6338311839050805 and parameters: {'C': 39.94216098464766}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63338\n",
      "Valid Accuracy: 0.64021\n",
      "[I 2025-07-20 19:13:21,169] Trial 66 finished with value: 0.633383500520888 and parameters: {'C': 20.203523997893402}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63364\n",
      "Valid Accuracy: 0.64103\n",
      "[I 2025-07-20 19:13:21,657] Trial 67 finished with value: 0.6336351086485559 and parameters: {'C': 0.024825657054624983}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63361\n",
      "Valid Accuracy: 0.64066\n",
      "[I 2025-07-20 19:13:22,119] Trial 68 finished with value: 0.633606574215881 and parameters: {'C': 4.444747547487028}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63404\n",
      "Valid Accuracy: 0.63971\n",
      "[I 2025-07-20 19:13:22,568] Trial 69 finished with value: 0.6340374361617649 and parameters: {'C': 22.420749957345052}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63380\n",
      "Valid Accuracy: 0.64022\n",
      "[I 2025-07-20 19:13:23,090] Trial 70 finished with value: 0.6338007697188545 and parameters: {'C': 53.069241198571305}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63272\n",
      "Valid Accuracy: 0.64113\n",
      "[I 2025-07-20 19:13:23,545] Trial 71 finished with value: 0.6327203339530977 and parameters: {'C': 1.2995359585237487}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63418\n",
      "Valid Accuracy: 0.63998\n",
      "[I 2025-07-20 19:13:24,053] Trial 72 finished with value: 0.6341835138384838 and parameters: {'C': 1.525524462147363}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63333\n",
      "Valid Accuracy: 0.64157\n",
      "[I 2025-07-20 19:13:24,525] Trial 73 finished with value: 0.6333251960506296 and parameters: {'C': 0.7856062995829464}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63444\n",
      "Valid Accuracy: 0.63987\n",
      "[I 2025-07-20 19:13:25,038] Trial 74 finished with value: 0.6344432673902727 and parameters: {'C': 0.0972725653732348}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63578\n",
      "Valid Accuracy: 0.63893\n",
      "[I 2025-07-20 19:13:25,497] Trial 75 finished with value: 0.6357822894586411 and parameters: {'C': 1.527092093596731}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.63310\n",
      "Valid Accuracy: 0.64216\n",
      "[I 2025-07-20 19:13:28,035] Trial 76 finished with value: 0.6330971804046287 and parameters: {'C': 3.830895761924959}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63260\n",
      "Valid Accuracy: 0.64185\n",
      "[I 2025-07-20 19:13:28,859] Trial 77 finished with value: 0.6325993600254327 and parameters: {'C': 1.8185716103969087}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63307\n",
      "Valid Accuracy: 0.64097\n",
      "[I 2025-07-20 19:13:29,341] Trial 78 finished with value: 0.6330688585090615 and parameters: {'C': 0.47060448532103066}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63439\n",
      "Valid Accuracy: 0.63926\n",
      "[I 2025-07-20 19:13:29,798] Trial 79 finished with value: 0.6343864234378193 and parameters: {'C': 11.504117330828484}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63409\n",
      "Valid Accuracy: 0.64040\n",
      "[I 2025-07-20 19:13:30,278] Trial 80 finished with value: 0.6340933067637718 and parameters: {'C': 1.8610862311263539}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63431\n",
      "Valid Accuracy: 0.64049\n",
      "[I 2025-07-20 19:13:30,813] Trial 81 finished with value: 0.6343116160858612 and parameters: {'C': 0.8525718413478066}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63371\n",
      "Valid Accuracy: 0.63990\n",
      "[I 2025-07-20 19:13:31,288] Trial 82 finished with value: 0.6337059502980454 and parameters: {'C': 3.2495796611363366}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63362\n",
      "Valid Accuracy: 0.63976\n",
      "[I 2025-07-20 19:13:31,764] Trial 83 finished with value: 0.6336234700106685 and parameters: {'C': 34.53297704483569}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63327\n",
      "Valid Accuracy: 0.64105\n",
      "[I 2025-07-20 19:13:32,302] Trial 84 finished with value: 0.6332722945234055 and parameters: {'C': 92.89463199135714}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63345\n",
      "Valid Accuracy: 0.64063\n",
      "[I 2025-07-20 19:13:32,806] Trial 85 finished with value: 0.6334518247092387 and parameters: {'C': 0.39275593611965726}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63374\n",
      "Valid Accuracy: 0.63907\n",
      "[I 2025-07-20 19:13:33,284] Trial 86 finished with value: 0.6337391626038319 and parameters: {'C': 1.9974985122692988}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63369\n",
      "Valid Accuracy: 0.63936\n",
      "[I 2025-07-20 19:13:33,764] Trial 87 finished with value: 0.6336910899690904 and parameters: {'C': 0.18252381556853728}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63443\n",
      "Valid Accuracy: 0.63999\n",
      "[I 2025-07-20 19:13:34,604] Trial 88 finished with value: 0.6344319693652319 and parameters: {'C': 54.28292169696621}. Best is trial 27 with value: 0.6320165003419045.\n",
      "Training time: 00:00:00\n",
      "Valid Log Loss: 0.63412\n",
      "Valid Accuracy: 0.63867\n",
      "[I 2025-07-20 19:13:35,116] Trial 89 finished with value: 0.6341213413941232 and parameters: {'C': 5.331102609785082}. Best is trial 27 with value: 0.6320165003419045.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x7723f7dbe110>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tr_df4_1\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "objective = op.create_objective(tr_df4_1)\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=30,\n",
    "    study_name=\"logreg_v6\",\n",
    "    storage=url,\n",
    "    # sampler=random_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee546e32-2aaf-4d1c-8d34-715c57ebb288",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 01:06:35,067] A new study created in RDB with name: logreg_v4.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f1d37c1b224991971db8a505e5f8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21170\n",
      "Valid Accuracy: 0.93980\n",
      "[I 2025-07-20 01:06:38,053] Trial 0 finished with value: 0.2117047464496658 and parameters: {'C': 93.3570709550824}. Best is trial 0 with value: 0.2117047464496658.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21094\n",
      "Valid Accuracy: 0.93998\n",
      "[I 2025-07-20 01:06:39,376] Trial 1 finished with value: 0.2109363433988954 and parameters: {'C': 0.11391337268914487}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.21216\n",
      "Valid Accuracy: 0.93977\n",
      "[I 2025-07-20 01:06:41,932] Trial 2 finished with value: 0.21215648159960723 and parameters: {'C': 0.0666604296958828}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21192\n",
      "Valid Accuracy: 0.93976\n",
      "[I 2025-07-20 01:06:43,444] Trial 3 finished with value: 0.21191537095333002 and parameters: {'C': 9.263752012793217}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.21147\n",
      "Valid Accuracy: 0.93998\n",
      "[I 2025-07-20 01:06:45,870] Trial 4 finished with value: 0.2114669420374136 and parameters: {'C': 0.03096140171948966}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21178\n",
      "Valid Accuracy: 0.93985\n",
      "[I 2025-07-20 01:06:47,264] Trial 5 finished with value: 0.21178303427027523 and parameters: {'C': 83.45105169850352}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21153\n",
      "Valid Accuracy: 0.93963\n",
      "[I 2025-07-20 01:06:49,316] Trial 6 finished with value: 0.21153090753456957 and parameters: {'C': 0.01309128278661112}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.21108\n",
      "Valid Accuracy: 0.93985\n",
      "[I 2025-07-20 01:06:51,955] Trial 7 finished with value: 0.211077202008799 and parameters: {'C': 0.10956279906730933}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:01\n",
      "Valid Log Loss: 0.21188\n",
      "Valid Accuracy: 0.93978\n",
      "[I 2025-07-20 01:06:53,372] Trial 8 finished with value: 0.2118825013099199 and parameters: {'C': 17.25296520646538}. Best is trial 1 with value: 0.2109363433988954.\n",
      "Training time: 00:00:02\n",
      "Valid Log Loss: 0.21057\n",
      "Valid Accuracy: 0.93989\n",
      "[I 2025-07-20 01:06:55,730] Trial 9 finished with value: 0.21057143658950117 and parameters: {'C': 0.0732184010963745}. Best is trial 9 with value: 0.21057143658950117.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x711d18b56a70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tr_df3_1\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "objective = op.create_objective(tr_df3_1)\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=10,\n",
    "    study_name=\"logreg_v4.1\",\n",
    "    storage=url,\n",
    "    # sampler=random_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110d1944-bca6-47c7-9f7a-4e61eee55422",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-19 01:54:32,641] Using an existing study with name 'logreg_v3' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9320db02dd99459fb6375d800f45f954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:17:41\n",
      "Valid Log Loss: 0.20910\n",
      "Valid Accuracy: 0.93943\n",
      "[I 2025-07-19 02:12:15,742] Trial 2 finished with value: 0.20910350751242435 and parameters: {'C': 1.8848175879481617, 'penalty': 'l2'}. Best is trial 0 with value: 0.20901691660591315.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:21:38\n",
      "Valid Log Loss: 0.20901\n",
      "Valid Accuracy: 0.93949\n",
      "[I 2025-07-19 02:33:55,515] Trial 3 finished with value: 0.20901296233246905 and parameters: {'C': 6.258843509756425, 'penalty': 'l2'}. Best is trial 3 with value: 0.20901296233246905.\n",
      "Training time: 00:16:55\n",
      "Valid Log Loss: 0.20912\n",
      "Valid Accuracy: 0.93945\n",
      "[I 2025-07-19 02:50:51,761] Trial 4 finished with value: 0.20912404428086206 and parameters: {'C': 1.6203221427601968, 'penalty': 'l2'}. Best is trial 3 with value: 0.20901296233246905.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 00:21:36\n",
      "Valid Log Loss: 0.20901\n",
      "Valid Accuracy: 0.93949\n",
      "[I 2025-07-19 03:12:29,512] Trial 5 finished with value: 0.20900832085435486 and parameters: {'C': 7.272605409622588, 'penalty': 'l2'}. Best is trial 5 with value: 0.20900832085435486.\n",
      "Training time: 00:20:39\n",
      "Valid Log Loss: 0.20905\n",
      "Valid Accuracy: 0.93947\n",
      "[I 2025-07-19 03:33:10,094] Trial 6 finished with value: 0.20904716078532107 and parameters: {'C': 3.2634088459295207, 'penalty': 'l2'}. Best is trial 5 with value: 0.20900832085435486.\n",
      "[W 2025-07-19 03:36:25,616] Trial 7 failed with parameters: {'C': 4.058497136802884, 'penalty': 'l2'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\hanse\\kaggle\\calorie\\src\\models\\logreg\\logreg_optuna_optimizer.py\", line 42, in objective\n",
      "    trainer.fit_one_fold(tr_df, fold=0)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hanse\\kaggle\\calorie\\src\\models\\logreg\\logreg_cv_trainer.py\", line 196, in fit_one_fold\n",
      "    pred_labels = model.predict(X_val)\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1350, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "        path_func(\n",
      "    ...<20 lines>...\n",
      "        for class_, warm_start_coef_ in zip(classes_, warm_start_coef)\n",
      "    )\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ~~~~^^^^^^^^\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"C:\\Users\\hanse\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1762, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "    ~~~~~~~~~~^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-19 03:36:25,632] Trial 7 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m objective \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mcreate_objective(\n\u001b[0;32m      5\u001b[0m     tr_df4,\n\u001b[0;32m      6\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m random_sampler \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mRandomSampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m op\u001b[38;5;241m.\u001b[39mrun_optuna_search(\n\u001b[0;32m     12\u001b[0m     objective,\n\u001b[0;32m     13\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m     14\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     15\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogreg_v3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     storage\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# sampler=random_sampler\u001b[39;00m\n\u001b[0;32m     18\u001b[0m )\n",
      "File \u001b[1;32m~\\kaggle\\calorie\\src\\models\\logreg\\logreg_optuna_optimizer.py:88\u001b[0m, in \u001b[0;36mrun_optuna_search\u001b[1;34m(objective, n_trials, n_jobs, study_name, storage, initial_params, sampler)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     study\u001b[38;5;241m.\u001b[39menqueue_trial(initial_params)\n\u001b[1;32m---> 88\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[0;32m     89\u001b[0m     objective,\n\u001b[0;32m     90\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m     91\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m     92\u001b[0m     show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     93\u001b[0m )\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    389\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m     _optimize(\n\u001b[0;32m    490\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    491\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    492\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    493\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    494\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    495\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    496\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    497\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    498\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    499\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m         _optimize_sequential(\n\u001b[0;32m     65\u001b[0m             study,\n\u001b[0;32m     66\u001b[0m             func,\n\u001b[0;32m     67\u001b[0m             n_trials,\n\u001b[0;32m     68\u001b[0m             timeout,\n\u001b[0;32m     69\u001b[0m             catch,\n\u001b[0;32m     70\u001b[0m             callbacks,\n\u001b[0;32m     71\u001b[0m             gc_after_trial,\n\u001b[0;32m     72\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     73\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     74\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     75\u001b[0m         )\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    249\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    252\u001b[0m ):\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[1;32m~\\kaggle\\calorie\\src\\models\\logreg\\logreg_optuna_optimizer.py:42\u001b[0m, in \u001b[0;36mcreate_objective.<locals>.objective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     28\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1e2\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m     36\u001b[0m }\n\u001b[0;32m     38\u001b[0m trainer \u001b[38;5;241m=\u001b[39m LogRegCVTrainer(\n\u001b[0;32m     39\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams, n_splits\u001b[38;5;241m=\u001b[39mn_splits\n\u001b[0;32m     40\u001b[0m )\n\u001b[1;32m---> 42\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit_one_fold(tr_df, fold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mfold_scores[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\kaggle\\calorie\\src\\models\\logreg\\logreg_cv_trainer.py:196\u001b[0m, in \u001b[0;36mfit_one_fold\u001b[1;34m(self, tr_df, fold, sample_weights)\u001b[0m\n\u001b[0;32m    193\u001b[0m print_duration(start, end)\n\u001b[0;32m    195\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)\n\u001b[1;32m--> 196\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m    197\u001b[0m logloss \u001b[38;5;241m=\u001b[39m log_loss(y_val, preds)\n\u001b[0;32m    198\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_val, pred_labels)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1350\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1350\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, prefer\u001b[38;5;241m=\u001b[39mprefer)(\n\u001b[0;32m   1351\u001b[0m     path_func(\n\u001b[0;32m   1352\u001b[0m         X,\n\u001b[0;32m   1353\u001b[0m         y,\n\u001b[0;32m   1354\u001b[0m         pos_class\u001b[38;5;241m=\u001b[39mclass_,\n\u001b[0;32m   1355\u001b[0m         Cs\u001b[38;5;241m=\u001b[39m[C_],\n\u001b[0;32m   1356\u001b[0m         l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[0;32m   1357\u001b[0m         fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[0;32m   1358\u001b[0m         tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m   1359\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   1360\u001b[0m         solver\u001b[38;5;241m=\u001b[39msolver,\n\u001b[0;32m   1361\u001b[0m         multi_class\u001b[38;5;241m=\u001b[39mmulti_class,\n\u001b[0;32m   1362\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m   1363\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m   1364\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1365\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m   1366\u001b[0m         coef\u001b[38;5;241m=\u001b[39mwarm_start_coef_,\n\u001b[0;32m   1367\u001b[0m         penalty\u001b[38;5;241m=\u001b[39mpenalty,\n\u001b[0;32m   1368\u001b[0m         max_squared_sum\u001b[38;5;241m=\u001b[39mmax_squared_sum,\n\u001b[0;32m   1369\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1370\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m   1371\u001b[0m     )\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_, warm_start_coef_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(classes_, warm_start_coef)\n\u001b[0;32m   1373\u001b[0m )\n\u001b[0;32m   1375\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tr_df4\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "objective = op.create_objective(tr_df4)\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=30,\n",
    "    study_name=\"logreg_v3\",\n",
    "    storage=url,\n",
    "    # sampler=random_sampler\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.12",
   "language": "python",
   "name": "rapids-23.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
