{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9eb2fb4-1988-41de-88e3-2b07048a0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import importlib\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import src.models.lgbm.lgbm_cv_trainer as cv\n",
    "import src.models.lgbm.lgbm_optuna_optimizer as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1443cab-6c7f-48e7-950e-2317ccc99379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "env_path = Path.cwd().parent / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "url = os.environ.get(\"OPTUNA_STORAGE_URL\")\n",
    "\n",
    "tr_df1 = pd.read_csv(\"../artifacts/features/tr_df1.csv\")\n",
    "test_df1 = pd.read_csv(\"../artifacts/features/test_df1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac49c7d5-02bf-4f2f-b9a0-79a294a584e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 20:25:56,664] A new study created in RDB with name: lgbm_v1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e9b49eaaee4944a4d236db9711a4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttrain's rmse: 0.0671054\teval's rmse: 0.0664504\n",
      "[200]\ttrain's rmse: 0.0638185\teval's rmse: 0.063258\n",
      "[300]\ttrain's rmse: 0.062945\teval's rmse: 0.0624499\n",
      "[400]\ttrain's rmse: 0.0625537\teval's rmse: 0.0621067\n",
      "[500]\ttrain's rmse: 0.0622817\teval's rmse: 0.061874\n",
      "[600]\ttrain's rmse: 0.0620215\teval's rmse: 0.0616563\n",
      "[700]\ttrain's rmse: 0.0618602\teval's rmse: 0.0615309\n",
      "[800]\ttrain's rmse: 0.061722\teval's rmse: 0.0614297\n",
      "[900]\ttrain's rmse: 0.0615776\teval's rmse: 0.0613269\n",
      "[1000]\ttrain's rmse: 0.0614737\teval's rmse: 0.0612611\n",
      "[1100]\ttrain's rmse: 0.0613757\teval's rmse: 0.0611939\n",
      "[1200]\ttrain's rmse: 0.0612796\teval's rmse: 0.0611299\n",
      "[1300]\ttrain's rmse: 0.0611961\teval's rmse: 0.0610858\n",
      "[1400]\ttrain's rmse: 0.0611174\teval's rmse: 0.0610372\n",
      "[1500]\ttrain's rmse: 0.0610481\teval's rmse: 0.0609975\n",
      "[1600]\ttrain's rmse: 0.0609864\teval's rmse: 0.0609606\n",
      "[1700]\ttrain's rmse: 0.0609353\teval's rmse: 0.0609394\n",
      "[1800]\ttrain's rmse: 0.0608772\teval's rmse: 0.0609084\n",
      "[1900]\ttrain's rmse: 0.0608159\teval's rmse: 0.0608773\n",
      "[2000]\ttrain's rmse: 0.0607709\teval's rmse: 0.0608514\n",
      "[2100]\ttrain's rmse: 0.0607219\teval's rmse: 0.0608284\n",
      "[2200]\ttrain's rmse: 0.0606788\teval's rmse: 0.0608096\n",
      "[2300]\ttrain's rmse: 0.060637\teval's rmse: 0.060788\n",
      "[2400]\ttrain's rmse: 0.0606009\teval's rmse: 0.0607707\n",
      "[2500]\ttrain's rmse: 0.0605599\teval's rmse: 0.0607507\n",
      "[2600]\ttrain's rmse: 0.0605284\teval's rmse: 0.0607407\n",
      "[2700]\ttrain's rmse: 0.0604892\teval's rmse: 0.0607263\n",
      "[2800]\ttrain's rmse: 0.0604553\teval's rmse: 0.0607113\n",
      "[2900]\ttrain's rmse: 0.0604234\teval's rmse: 0.0607014\n",
      "[3000]\ttrain's rmse: 0.0603909\teval's rmse: 0.0606885\n",
      "[3100]\ttrain's rmse: 0.0603598\teval's rmse: 0.0606787\n",
      "[3200]\ttrain's rmse: 0.0603317\teval's rmse: 0.0606707\n",
      "[3300]\ttrain's rmse: 0.0603013\teval's rmse: 0.06066\n",
      "[3400]\ttrain's rmse: 0.0602743\teval's rmse: 0.0606517\n",
      "[3500]\ttrain's rmse: 0.0602499\teval's rmse: 0.0606407\n",
      "[3600]\ttrain's rmse: 0.0602259\teval's rmse: 0.0606374\n",
      "[3700]\ttrain's rmse: 0.0601992\teval's rmse: 0.0606273\n",
      "[3800]\ttrain's rmse: 0.0601751\teval's rmse: 0.0606198\n",
      "[3900]\ttrain's rmse: 0.0601535\teval's rmse: 0.0606127\n",
      "[4000]\ttrain's rmse: 0.0601312\teval's rmse: 0.0606104\n",
      "[4100]\ttrain's rmse: 0.0601067\teval's rmse: 0.060603\n",
      "[4200]\ttrain's rmse: 0.0600866\teval's rmse: 0.0605993\n",
      "[4300]\ttrain's rmse: 0.0600658\teval's rmse: 0.0605939\n",
      "[4400]\ttrain's rmse: 0.0600445\teval's rmse: 0.0605886\n",
      "[4500]\ttrain's rmse: 0.0600233\teval's rmse: 0.0605826\n",
      "[4600]\ttrain's rmse: 0.0600016\teval's rmse: 0.0605774\n",
      "[4700]\ttrain's rmse: 0.0599831\teval's rmse: 0.0605733\n",
      "[4800]\ttrain's rmse: 0.0599664\teval's rmse: 0.0605712\n",
      "[4900]\ttrain's rmse: 0.0599462\teval's rmse: 0.0605636\n",
      "[5000]\ttrain's rmse: 0.0599276\teval's rmse: 0.0605603\n",
      "[5100]\ttrain's rmse: 0.0599081\teval's rmse: 0.0605575\n",
      "[5200]\ttrain's rmse: 0.0598894\teval's rmse: 0.0605541\n",
      "[5300]\ttrain's rmse: 0.0598741\teval's rmse: 0.0605492\n",
      "[5400]\ttrain's rmse: 0.0598557\teval's rmse: 0.0605481\n",
      "[5500]\ttrain's rmse: 0.0598377\teval's rmse: 0.0605453\n",
      "[5600]\ttrain's rmse: 0.0598233\teval's rmse: 0.0605431\n",
      "[5700]\ttrain's rmse: 0.0598069\teval's rmse: 0.0605406\n",
      "[5800]\ttrain's rmse: 0.0597896\teval's rmse: 0.0605354\n",
      "[5900]\ttrain's rmse: 0.0597725\teval's rmse: 0.0605323\n",
      "[6000]\ttrain's rmse: 0.0597563\teval's rmse: 0.060532\n",
      "[6100]\ttrain's rmse: 0.0597409\teval's rmse: 0.0605292\n",
      "[6200]\ttrain's rmse: 0.0597288\teval's rmse: 0.0605297\n",
      "[6300]\ttrain's rmse: 0.0597105\teval's rmse: 0.0605261\n",
      "[6400]\ttrain's rmse: 0.0596955\teval's rmse: 0.0605216\n",
      "[6500]\ttrain's rmse: 0.0596806\teval's rmse: 0.0605214\n",
      "[6600]\ttrain's rmse: 0.0596645\teval's rmse: 0.0605161\n",
      "[6700]\ttrain's rmse: 0.0596493\teval's rmse: 0.0605156\n",
      "[6800]\ttrain's rmse: 0.0596332\teval's rmse: 0.0605118\n",
      "[6900]\ttrain's rmse: 0.0596198\teval's rmse: 0.0605103\n",
      "[7000]\ttrain's rmse: 0.0596063\teval's rmse: 0.0605115\n",
      "[7100]\ttrain's rmse: 0.0595938\teval's rmse: 0.0605092\n",
      "[7200]\ttrain's rmse: 0.059582\teval's rmse: 0.0605081\n",
      "[7300]\ttrain's rmse: 0.0595669\teval's rmse: 0.0605058\n",
      "[7400]\ttrain's rmse: 0.0595541\teval's rmse: 0.060505\n",
      "[7500]\ttrain's rmse: 0.0595399\teval's rmse: 0.0605\n",
      "[7600]\ttrain's rmse: 0.0595272\teval's rmse: 0.060496\n",
      "[7700]\ttrain's rmse: 0.0595156\teval's rmse: 0.0604983\n",
      "[7800]\ttrain's rmse: 0.0595028\teval's rmse: 0.0604982\n",
      "[7900]\ttrain's rmse: 0.0594901\teval's rmse: 0.0604958\n",
      "[8000]\ttrain's rmse: 0.0594785\teval's rmse: 0.0604948\n",
      "[8100]\ttrain's rmse: 0.0594657\teval's rmse: 0.0604893\n",
      "[8200]\ttrain's rmse: 0.0594539\teval's rmse: 0.0604911\n",
      "[8300]\ttrain's rmse: 0.059443\teval's rmse: 0.0604907\n",
      "[8400]\ttrain's rmse: 0.0594305\teval's rmse: 0.0604852\n",
      "[8500]\ttrain's rmse: 0.0594188\teval's rmse: 0.0604813\n",
      "[8600]\ttrain's rmse: 0.0594064\teval's rmse: 0.0604851\n",
      "[8700]\ttrain's rmse: 0.0593953\teval's rmse: 0.060484\n",
      "[8800]\ttrain's rmse: 0.0593825\teval's rmse: 0.060483\n",
      "[8900]\ttrain's rmse: 0.0593724\teval's rmse: 0.0604861\n",
      "[9000]\ttrain's rmse: 0.0593599\teval's rmse: 0.0604824\n",
      "Early stopping, best iteration is:\n",
      "[8506]\ttrain's rmse: 0.0594175\teval's rmse: 0.0604813\n",
      "Training time: 00:12:37\n",
      "Train rmse: 0.05942\n",
      "Valid rmse: 0.06048\n",
      "[I 2025-07-20 20:38:34,450] Trial 0 finished with value: 0.060481305339152816 and parameters: {'max_depth': 5, 'num_leaves': 523, 'min_child_samples': 5056, 'min_split_gain': 9.275294835907687e-05, 'feature_fraction': 0.43593953046851464, 'bagging_fraction': 0.8924361138693251, 'bagging_freq': 10, 'lambda_l1': 1.6934155410667961, 'lambda_l2': 0.6637926838138378}. Best is trial 0 with value: 0.060481305339152816.\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttrain's rmse: 0.0959502\teval's rmse: 0.0952494\n",
      "[200]\ttrain's rmse: 0.0818458\teval's rmse: 0.0812371\n",
      "[300]\ttrain's rmse: 0.0776519\teval's rmse: 0.0770802\n",
      "[400]\ttrain's rmse: 0.0761474\teval's rmse: 0.0755858\n",
      "[500]\ttrain's rmse: 0.0755524\teval's rmse: 0.0749984\n",
      "[600]\ttrain's rmse: 0.0753416\teval's rmse: 0.0747897\n",
      "[700]\ttrain's rmse: 0.0752366\teval's rmse: 0.0746885\n",
      "[800]\ttrain's rmse: 0.0751922\teval's rmse: 0.0746478\n",
      "[900]\ttrain's rmse: 0.0751601\teval's rmse: 0.0746158\n",
      "[1000]\ttrain's rmse: 0.0751336\teval's rmse: 0.0745911\n",
      "[1100]\ttrain's rmse: 0.0751209\teval's rmse: 0.07458\n",
      "[1200]\ttrain's rmse: 0.0751147\teval's rmse: 0.074573\n",
      "[1300]\ttrain's rmse: 0.0751069\teval's rmse: 0.0745654\n",
      "[1400]\ttrain's rmse: 0.0750997\teval's rmse: 0.0745581\n",
      "[1500]\ttrain's rmse: 0.0750942\teval's rmse: 0.0745506\n",
      "[1600]\ttrain's rmse: 0.0750916\teval's rmse: 0.0745469\n",
      "[1700]\ttrain's rmse: 0.0750894\teval's rmse: 0.0745452\n",
      "[1800]\ttrain's rmse: 0.0750812\teval's rmse: 0.074536\n",
      "[1900]\ttrain's rmse: 0.0750788\teval's rmse: 0.0745339\n",
      "[2000]\ttrain's rmse: 0.075077\teval's rmse: 0.0745317\n",
      "[2100]\ttrain's rmse: 0.075075\teval's rmse: 0.0745296\n",
      "[2200]\ttrain's rmse: 0.0750719\teval's rmse: 0.0745273\n",
      "[2300]\ttrain's rmse: 0.0750707\teval's rmse: 0.0745265\n",
      "[2400]\ttrain's rmse: 0.0750698\teval's rmse: 0.0745266\n",
      "[2500]\ttrain's rmse: 0.0750688\teval's rmse: 0.074525\n",
      "[2600]\ttrain's rmse: 0.075067\teval's rmse: 0.0745236\n",
      "[2700]\ttrain's rmse: 0.0750662\teval's rmse: 0.0745228\n",
      "[2800]\ttrain's rmse: 0.075065\teval's rmse: 0.0745228\n",
      "[2900]\ttrain's rmse: 0.0750642\teval's rmse: 0.0745215\n",
      "[3000]\ttrain's rmse: 0.0750634\teval's rmse: 0.0745208\n",
      "[3100]\ttrain's rmse: 0.0750622\teval's rmse: 0.0745199\n",
      "[3200]\ttrain's rmse: 0.0750617\teval's rmse: 0.0745206\n",
      "[3300]\ttrain's rmse: 0.0750611\teval's rmse: 0.0745198\n",
      "[3400]\ttrain's rmse: 0.0750543\teval's rmse: 0.074514\n",
      "[3500]\ttrain's rmse: 0.0750532\teval's rmse: 0.0745125\n",
      "[3600]\ttrain's rmse: 0.0750524\teval's rmse: 0.0745104\n",
      "[3700]\ttrain's rmse: 0.0750515\teval's rmse: 0.0745097\n",
      "[3800]\ttrain's rmse: 0.0750498\teval's rmse: 0.074508\n",
      "[3900]\ttrain's rmse: 0.0750486\teval's rmse: 0.0745062\n",
      "[4000]\ttrain's rmse: 0.0750484\teval's rmse: 0.0745064\n",
      "[4100]\ttrain's rmse: 0.075048\teval's rmse: 0.0745055\n",
      "[4200]\ttrain's rmse: 0.0750472\teval's rmse: 0.0745047\n",
      "[4300]\ttrain's rmse: 0.0750472\teval's rmse: 0.0745044\n",
      "[4400]\ttrain's rmse: 0.075047\teval's rmse: 0.0745045\n",
      "[4500]\ttrain's rmse: 0.0750465\teval's rmse: 0.0745044\n",
      "[4600]\ttrain's rmse: 0.0750463\teval's rmse: 0.0745041\n",
      "[4700]\ttrain's rmse: 0.075046\teval's rmse: 0.0745045\n",
      "Early stopping, best iteration is:\n",
      "[4251]\ttrain's rmse: 0.0750472\teval's rmse: 0.0745036\n",
      "Training time: 00:00:46\n",
      "Train rmse: 0.07505\n",
      "Valid rmse: 0.07450\n",
      "[I 2025-07-20 20:39:20,786] Trial 1 finished with value: 0.07450358774306105 and parameters: {'max_depth': 7, 'num_leaves': 591, 'min_child_samples': 6196, 'min_split_gain': 0.039079671568228794, 'feature_fraction': 0.32340279606636546, 'bagging_fraction': 0.6967983561008608, 'bagging_freq': 1, 'lambda_l1': 1.574189004745663, 'lambda_l2': 0.040428727350273294}. Best is trial 0 with value: 0.060481305339152816.\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttrain's rmse: 0.0975424\teval's rmse: 0.0968425\n",
      "[200]\ttrain's rmse: 0.0854529\teval's rmse: 0.0848301\n",
      "[300]\ttrain's rmse: 0.0823086\teval's rmse: 0.0817066\n",
      "[400]\ttrain's rmse: 0.0812146\teval's rmse: 0.0806181\n",
      "[500]\ttrain's rmse: 0.0807196\teval's rmse: 0.0801213\n",
      "[600]\ttrain's rmse: 0.080636\teval's rmse: 0.0800368\n",
      "[700]\ttrain's rmse: 0.0805878\teval's rmse: 0.0799896\n",
      "[800]\ttrain's rmse: 0.0805878\teval's rmse: 0.0799896\n",
      "[900]\ttrain's rmse: 0.0805878\teval's rmse: 0.0799896\n",
      "[1000]\ttrain's rmse: 0.0805878\teval's rmse: 0.0799896\n",
      "[1100]\ttrain's rmse: 0.0805878\teval's rmse: 0.0799896\n",
      "Early stopping, best iteration is:\n",
      "[624]\ttrain's rmse: 0.0805878\teval's rmse: 0.0799896\n",
      "Training time: 00:00:11\n",
      "Train rmse: 0.08059\n",
      "Valid rmse: 0.07999\n",
      "[I 2025-07-20 20:39:32,432] Trial 2 finished with value: 0.0799895916383916 and parameters: {'max_depth': 9, 'num_leaves': 404, 'min_child_samples': 6910, 'min_split_gain': 0.9877700294007907, 'feature_fraction': 0.3318508666017414, 'bagging_fraction': 0.7045474901621303, 'bagging_freq': 3, 'lambda_l1': 0.0006690421166498799, 'lambda_l2': 0.014077923139972392}. Best is trial 0 with value: 0.060481305339152816.\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttrain's rmse: 0.0950737\teval's rmse: 0.0944261\n",
      "[200]\ttrain's rmse: 0.0811558\teval's rmse: 0.0806274\n",
      "[300]\ttrain's rmse: 0.0764852\teval's rmse: 0.0759998\n",
      "[400]\ttrain's rmse: 0.0745498\teval's rmse: 0.0740896\n",
      "[500]\ttrain's rmse: 0.0736518\teval's rmse: 0.0732133\n",
      "[600]\ttrain's rmse: 0.0731398\teval's rmse: 0.0727167\n",
      "[700]\ttrain's rmse: 0.0727364\teval's rmse: 0.0723254\n",
      "[800]\ttrain's rmse: 0.0724758\teval's rmse: 0.0720794\n",
      "[900]\ttrain's rmse: 0.0722635\teval's rmse: 0.0718843\n",
      "[1000]\ttrain's rmse: 0.0720148\teval's rmse: 0.0716476\n",
      "[1100]\ttrain's rmse: 0.0718225\teval's rmse: 0.0714687\n",
      "[1200]\ttrain's rmse: 0.0716254\teval's rmse: 0.07129\n",
      "[1300]\ttrain's rmse: 0.0714823\teval's rmse: 0.0711594\n",
      "[1400]\ttrain's rmse: 0.0713528\teval's rmse: 0.0710363\n",
      "[1500]\ttrain's rmse: 0.0712498\teval's rmse: 0.0709464\n",
      "[1600]\ttrain's rmse: 0.0711463\teval's rmse: 0.0708601\n",
      "[1700]\ttrain's rmse: 0.0710356\teval's rmse: 0.0707572\n",
      "[1800]\ttrain's rmse: 0.0709338\teval's rmse: 0.0706652\n",
      "[1900]\ttrain's rmse: 0.0708389\teval's rmse: 0.070585\n",
      "[2000]\ttrain's rmse: 0.0707669\teval's rmse: 0.0705246\n",
      "[2100]\ttrain's rmse: 0.0706904\teval's rmse: 0.0704623\n",
      "[2200]\ttrain's rmse: 0.0706415\teval's rmse: 0.0704238\n",
      "[2300]\ttrain's rmse: 0.0705955\teval's rmse: 0.0703835\n",
      "[2400]\ttrain's rmse: 0.070543\teval's rmse: 0.07034\n",
      "[2500]\ttrain's rmse: 0.0704951\teval's rmse: 0.0703081\n",
      "[2600]\ttrain's rmse: 0.0704576\teval's rmse: 0.0702762\n",
      "[2700]\ttrain's rmse: 0.0704238\teval's rmse: 0.07025\n",
      "[2800]\ttrain's rmse: 0.0703892\teval's rmse: 0.0702261\n",
      "[2900]\ttrain's rmse: 0.0703659\teval's rmse: 0.0702079\n",
      "[3000]\ttrain's rmse: 0.0703331\teval's rmse: 0.0701893\n",
      "[3100]\ttrain's rmse: 0.0703078\teval's rmse: 0.0701683\n",
      "[3200]\ttrain's rmse: 0.0702843\teval's rmse: 0.0701508\n",
      "[3300]\ttrain's rmse: 0.0702628\teval's rmse: 0.070139\n",
      "[3400]\ttrain's rmse: 0.0702367\teval's rmse: 0.0701203\n",
      "[3500]\ttrain's rmse: 0.07021\teval's rmse: 0.0701026\n",
      "[3600]\ttrain's rmse: 0.0701847\teval's rmse: 0.0700781\n",
      "[3700]\ttrain's rmse: 0.0701644\teval's rmse: 0.0700643\n",
      "[3800]\ttrain's rmse: 0.0701443\teval's rmse: 0.0700552\n",
      "[3900]\ttrain's rmse: 0.0701273\teval's rmse: 0.0700458\n",
      "[4000]\ttrain's rmse: 0.0701096\teval's rmse: 0.0700374\n",
      "[4100]\ttrain's rmse: 0.0700901\teval's rmse: 0.0700227\n",
      "[4200]\ttrain's rmse: 0.0700731\teval's rmse: 0.0700118\n",
      "[4300]\ttrain's rmse: 0.0700573\teval's rmse: 0.0700025\n",
      "[4400]\ttrain's rmse: 0.0700433\teval's rmse: 0.0699949\n",
      "[4500]\ttrain's rmse: 0.0700291\teval's rmse: 0.0699846\n",
      "[4600]\ttrain's rmse: 0.0700156\teval's rmse: 0.0699804\n",
      "[4700]\ttrain's rmse: 0.0700004\teval's rmse: 0.0699699\n",
      "[4800]\ttrain's rmse: 0.0699863\teval's rmse: 0.0699606\n",
      "[4900]\ttrain's rmse: 0.0699758\teval's rmse: 0.0699552\n",
      "[5000]\ttrain's rmse: 0.0699598\teval's rmse: 0.069946\n",
      "[5100]\ttrain's rmse: 0.0699462\teval's rmse: 0.069936\n",
      "[5200]\ttrain's rmse: 0.0699334\teval's rmse: 0.0699301\n",
      "[5300]\ttrain's rmse: 0.069921\teval's rmse: 0.0699247\n",
      "[5400]\ttrain's rmse: 0.0699131\teval's rmse: 0.069922\n",
      "[5500]\ttrain's rmse: 0.0699026\teval's rmse: 0.0699173\n",
      "[5600]\ttrain's rmse: 0.0698931\teval's rmse: 0.069913\n",
      "[5700]\ttrain's rmse: 0.0698851\teval's rmse: 0.0699094\n",
      "[5800]\ttrain's rmse: 0.0698745\teval's rmse: 0.0699031\n",
      "[5900]\ttrain's rmse: 0.0698655\teval's rmse: 0.0699009\n",
      "[6000]\ttrain's rmse: 0.069855\teval's rmse: 0.0698929\n",
      "[6100]\ttrain's rmse: 0.0698455\teval's rmse: 0.0698885\n",
      "[6200]\ttrain's rmse: 0.0698353\teval's rmse: 0.0698829\n",
      "[6300]\ttrain's rmse: 0.0698252\teval's rmse: 0.0698799\n",
      "[6400]\ttrain's rmse: 0.0698155\teval's rmse: 0.0698765\n",
      "[6500]\ttrain's rmse: 0.0698076\teval's rmse: 0.0698735\n",
      "[6600]\ttrain's rmse: 0.0697981\teval's rmse: 0.0698677\n",
      "[6700]\ttrain's rmse: 0.0697912\teval's rmse: 0.0698669\n",
      "[6800]\ttrain's rmse: 0.0697823\teval's rmse: 0.0698652\n",
      "[6900]\ttrain's rmse: 0.0697747\teval's rmse: 0.0698635\n",
      "[7000]\ttrain's rmse: 0.0697668\teval's rmse: 0.0698608\n",
      "[7100]\ttrain's rmse: 0.0697602\teval's rmse: 0.069859\n",
      "[7200]\ttrain's rmse: 0.0697522\teval's rmse: 0.0698568\n",
      "[7300]\ttrain's rmse: 0.0697445\teval's rmse: 0.0698558\n",
      "[7400]\ttrain's rmse: 0.0697362\teval's rmse: 0.069857\n",
      "[7500]\ttrain's rmse: 0.0697294\teval's rmse: 0.0698511\n",
      "[7600]\ttrain's rmse: 0.0697225\teval's rmse: 0.0698497\n",
      "[7700]\ttrain's rmse: 0.0697151\teval's rmse: 0.0698464\n",
      "[7800]\ttrain's rmse: 0.0697085\teval's rmse: 0.0698449\n",
      "[7900]\ttrain's rmse: 0.0697018\teval's rmse: 0.0698422\n",
      "[8000]\ttrain's rmse: 0.0696948\teval's rmse: 0.0698373\n",
      "[8100]\ttrain's rmse: 0.0696882\teval's rmse: 0.0698385\n",
      "[8200]\ttrain's rmse: 0.0696815\teval's rmse: 0.0698347\n",
      "[8300]\ttrain's rmse: 0.0696758\teval's rmse: 0.069835\n",
      "[8400]\ttrain's rmse: 0.0696701\teval's rmse: 0.0698307\n",
      "[8500]\ttrain's rmse: 0.0696635\teval's rmse: 0.0698277\n",
      "[8600]\ttrain's rmse: 0.0696578\teval's rmse: 0.0698266\n",
      "[8700]\ttrain's rmse: 0.0696522\teval's rmse: 0.0698242\n",
      "[8800]\ttrain's rmse: 0.0696474\teval's rmse: 0.0698224\n",
      "[8900]\ttrain's rmse: 0.0696433\teval's rmse: 0.0698233\n",
      "[9000]\ttrain's rmse: 0.0696368\teval's rmse: 0.0698233\n",
      "[9100]\ttrain's rmse: 0.0696311\teval's rmse: 0.0698198\n",
      "[9200]\ttrain's rmse: 0.0696254\teval's rmse: 0.0698177\n",
      "[9300]\ttrain's rmse: 0.0696201\teval's rmse: 0.0698177\n",
      "[9400]\ttrain's rmse: 0.0696153\teval's rmse: 0.0698164\n",
      "[9500]\ttrain's rmse: 0.0696097\teval's rmse: 0.0698135\n",
      "[9600]\ttrain's rmse: 0.0696053\teval's rmse: 0.0698154\n",
      "[9700]\ttrain's rmse: 0.0696008\teval's rmse: 0.0698147\n",
      "[9800]\ttrain's rmse: 0.0695961\teval's rmse: 0.0698113\n",
      "[9900]\ttrain's rmse: 0.0695906\teval's rmse: 0.0698095\n",
      "[10000]\ttrain's rmse: 0.0695851\teval's rmse: 0.0698095\n",
      "[10100]\ttrain's rmse: 0.069581\teval's rmse: 0.0698059\n",
      "[10200]\ttrain's rmse: 0.0695771\teval's rmse: 0.0698098\n",
      "[10300]\ttrain's rmse: 0.0695724\teval's rmse: 0.0698094\n",
      "[10400]\ttrain's rmse: 0.0695663\teval's rmse: 0.0698067\n",
      "[10500]\ttrain's rmse: 0.0695626\teval's rmse: 0.0698075\n",
      "[10600]\ttrain's rmse: 0.0695582\teval's rmse: 0.0698073\n",
      "[10700]\ttrain's rmse: 0.0695543\teval's rmse: 0.0698036\n",
      "[10800]\ttrain's rmse: 0.0695511\teval's rmse: 0.0698027\n",
      "[10900]\ttrain's rmse: 0.0695474\teval's rmse: 0.0698008\n",
      "[11000]\ttrain's rmse: 0.0695426\teval's rmse: 0.0698\n",
      "[11100]\ttrain's rmse: 0.0695392\teval's rmse: 0.0698013\n",
      "[11200]\ttrain's rmse: 0.0695339\teval's rmse: 0.0697994\n",
      "[11300]\ttrain's rmse: 0.0695294\teval's rmse: 0.0697976\n",
      "[11400]\ttrain's rmse: 0.069525\teval's rmse: 0.0697985\n",
      "[11500]\ttrain's rmse: 0.0695212\teval's rmse: 0.0697989\n",
      "[11600]\ttrain's rmse: 0.0695168\teval's rmse: 0.0697957\n",
      "[11700]\ttrain's rmse: 0.0695134\teval's rmse: 0.0697955\n",
      "[11800]\ttrain's rmse: 0.069509\teval's rmse: 0.0697935\n",
      "[11900]\ttrain's rmse: 0.0695053\teval's rmse: 0.0697888\n",
      "[12000]\ttrain's rmse: 0.0695019\teval's rmse: 0.0697917\n",
      "[12100]\ttrain's rmse: 0.0694971\teval's rmse: 0.0697894\n",
      "[12200]\ttrain's rmse: 0.0694926\teval's rmse: 0.0697882\n",
      "[12300]\ttrain's rmse: 0.0694883\teval's rmse: 0.0697869\n",
      "[12400]\ttrain's rmse: 0.0694836\teval's rmse: 0.0697859\n",
      "[12500]\ttrain's rmse: 0.0694799\teval's rmse: 0.069786\n",
      "[12600]\ttrain's rmse: 0.0694753\teval's rmse: 0.0697832\n",
      "[12700]\ttrain's rmse: 0.0694713\teval's rmse: 0.0697851\n",
      "[12800]\ttrain's rmse: 0.0694675\teval's rmse: 0.0697847\n",
      "[12900]\ttrain's rmse: 0.0694635\teval's rmse: 0.0697825\n",
      "[13000]\ttrain's rmse: 0.0694595\teval's rmse: 0.069783\n",
      "[13100]\ttrain's rmse: 0.0694562\teval's rmse: 0.0697835\n",
      "[13200]\ttrain's rmse: 0.0694528\teval's rmse: 0.0697841\n",
      "[13300]\ttrain's rmse: 0.0694489\teval's rmse: 0.069786\n",
      "[13400]\ttrain's rmse: 0.0694454\teval's rmse: 0.0697845\n",
      "[13500]\ttrain's rmse: 0.0694421\teval's rmse: 0.069783\n",
      "Early stopping, best iteration is:\n",
      "[13069]\ttrain's rmse: 0.0694574\teval's rmse: 0.0697805\n",
      "Training time: 00:14:10\n",
      "Train rmse: 0.06946\n",
      "Valid rmse: 0.06978\n",
      "[I 2025-07-20 20:53:42,957] Trial 3 finished with value: 0.06978046822954491 and parameters: {'max_depth': 7, 'num_leaves': 458, 'min_child_samples': 5836, 'min_split_gain': 6.870101665590028e-05, 'feature_fraction': 0.3438216972802827, 'bagging_fraction': 0.7599085529881076, 'bagging_freq': 7, 'lambda_l1': 0.5141096648805742, 'lambda_l2': 0.00015777663630582464}. Best is trial 0 with value: 0.060481305339152816.\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttrain's rmse: 0.0944364\teval's rmse: 0.0938226\n",
      "[200]\ttrain's rmse: 0.0806933\teval's rmse: 0.0801755\n",
      "[300]\ttrain's rmse: 0.0766276\teval's rmse: 0.0761388\n",
      "[400]\ttrain's rmse: 0.0752226\teval's rmse: 0.0747385\n",
      "[500]\ttrain's rmse: 0.0747056\teval's rmse: 0.0742133\n",
      "[600]\ttrain's rmse: 0.0746233\teval's rmse: 0.0741286\n",
      "[700]\ttrain's rmse: 0.0745642\teval's rmse: 0.0740744\n",
      "[800]\ttrain's rmse: 0.0745456\teval's rmse: 0.0740562\n",
      "[900]\ttrain's rmse: 0.0745456\teval's rmse: 0.0740562\n",
      "[1000]\ttrain's rmse: 0.0745456\teval's rmse: 0.0740562\n",
      "[1100]\ttrain's rmse: 0.0745456\teval's rmse: 0.0740562\n",
      "[1200]\ttrain's rmse: 0.0745456\teval's rmse: 0.0740562\n",
      "[1300]\ttrain's rmse: 0.0745456\teval's rmse: 0.0740562\n",
      "Early stopping, best iteration is:\n",
      "[806]\ttrain's rmse: 0.0745456\teval's rmse: 0.0740562\n",
      "Training time: 00:00:28\n",
      "Train rmse: 0.07455\n",
      "Valid rmse: 0.07406\n",
      "[I 2025-07-20 20:54:11,647] Trial 4 finished with value: 0.07405622290867822 and parameters: {'max_depth': 8, 'num_leaves': 519, 'min_child_samples': 4139, 'min_split_gain': 0.0441844152119972, 'feature_fraction': 0.3255786185530937, 'bagging_fraction': 0.6695154778955839, 'bagging_freq': 15, 'lambda_l1': 6.220025976819156, 'lambda_l2': 0.7085721663941598}. Best is trial 0 with value: 0.060481305339152816.\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttrain's rmse: 0.095132\teval's rmse: 0.0944901\n",
      "[200]\ttrain's rmse: 0.0811835\teval's rmse: 0.080649\n",
      "[300]\ttrain's rmse: 0.076584\teval's rmse: 0.076092\n",
      "[400]\ttrain's rmse: 0.0747356\teval's rmse: 0.0742675\n",
      "[500]\ttrain's rmse: 0.0739156\teval's rmse: 0.0734659\n",
      "[600]\ttrain's rmse: 0.073572\teval's rmse: 0.0731288\n",
      "[700]\ttrain's rmse: 0.0732541\teval's rmse: 0.0728193\n",
      "[800]\ttrain's rmse: 0.0730988\teval's rmse: 0.0726697\n",
      "[900]\ttrain's rmse: 0.0729833\teval's rmse: 0.072558\n",
      "[1000]\ttrain's rmse: 0.0728376\teval's rmse: 0.0724188\n",
      "[1100]\ttrain's rmse: 0.0727399\teval's rmse: 0.0723273\n",
      "[1200]\ttrain's rmse: 0.0726283\teval's rmse: 0.0722251\n",
      "[1300]\ttrain's rmse: 0.0725492\teval's rmse: 0.0721506\n",
      "[1400]\ttrain's rmse: 0.0724908\teval's rmse: 0.0720944\n",
      "[1500]\ttrain's rmse: 0.0724418\teval's rmse: 0.0720509\n",
      "[1600]\ttrain's rmse: 0.0724072\teval's rmse: 0.072018\n",
      "[1700]\ttrain's rmse: 0.0723827\teval's rmse: 0.0719947\n",
      "[1800]\ttrain's rmse: 0.072317\teval's rmse: 0.0719337\n",
      "[1900]\ttrain's rmse: 0.0722573\teval's rmse: 0.0718766\n",
      "[2000]\ttrain's rmse: 0.0722291\teval's rmse: 0.0718495\n",
      "[2100]\ttrain's rmse: 0.0722171\teval's rmse: 0.0718389\n",
      "[2200]\ttrain's rmse: 0.0722017\teval's rmse: 0.0718259\n",
      "[2300]\ttrain's rmse: 0.0721791\teval's rmse: 0.0718063\n",
      "[2400]\ttrain's rmse: 0.072158\teval's rmse: 0.0717871\n",
      "[2500]\ttrain's rmse: 0.0721315\teval's rmse: 0.0717619\n",
      "[2600]\ttrain's rmse: 0.0720831\teval's rmse: 0.0717186\n",
      "[2700]\ttrain's rmse: 0.0720571\teval's rmse: 0.0716937\n",
      "[2800]\ttrain's rmse: 0.072047\teval's rmse: 0.0716849\n",
      "[2900]\ttrain's rmse: 0.0720361\teval's rmse: 0.0716743\n",
      "[3000]\ttrain's rmse: 0.0720213\teval's rmse: 0.0716623\n",
      "[3100]\ttrain's rmse: 0.0720057\teval's rmse: 0.0716449\n",
      "[3200]\ttrain's rmse: 0.071992\teval's rmse: 0.0716325\n",
      "[3300]\ttrain's rmse: 0.0719875\teval's rmse: 0.0716278\n",
      "[3400]\ttrain's rmse: 0.0719703\teval's rmse: 0.0716123\n",
      "[3500]\ttrain's rmse: 0.0719562\teval's rmse: 0.0715976\n",
      "[3600]\ttrain's rmse: 0.0719441\teval's rmse: 0.0715878\n",
      "[3700]\ttrain's rmse: 0.071939\teval's rmse: 0.0715851\n",
      "[3800]\ttrain's rmse: 0.0719325\teval's rmse: 0.0715797\n",
      "[3900]\ttrain's rmse: 0.071907\teval's rmse: 0.0715551\n",
      "[4000]\ttrain's rmse: 0.0718993\teval's rmse: 0.0715492\n",
      "[4100]\ttrain's rmse: 0.0718955\teval's rmse: 0.0715452\n",
      "[4200]\ttrain's rmse: 0.071889\teval's rmse: 0.0715378\n",
      "[4300]\ttrain's rmse: 0.071877\teval's rmse: 0.0715289\n",
      "[4400]\ttrain's rmse: 0.0718586\teval's rmse: 0.0715095\n",
      "[4500]\ttrain's rmse: 0.0718434\teval's rmse: 0.0714927\n",
      "[4600]\ttrain's rmse: 0.071835\teval's rmse: 0.0714848\n",
      "[4700]\ttrain's rmse: 0.0718131\teval's rmse: 0.0714636\n",
      "[4800]\ttrain's rmse: 0.0718083\teval's rmse: 0.0714594\n",
      "[4900]\ttrain's rmse: 0.0718016\teval's rmse: 0.0714552\n",
      "[5000]\ttrain's rmse: 0.0717925\teval's rmse: 0.0714483\n",
      "[5100]\ttrain's rmse: 0.0717835\teval's rmse: 0.0714392\n",
      "[5200]\ttrain's rmse: 0.0717578\teval's rmse: 0.0714151\n",
      "[5300]\ttrain's rmse: 0.071753\teval's rmse: 0.0714108\n",
      "[5400]\ttrain's rmse: 0.0717345\teval's rmse: 0.0713946\n",
      "[5500]\ttrain's rmse: 0.0717291\teval's rmse: 0.0713907\n",
      "[5600]\ttrain's rmse: 0.0717109\teval's rmse: 0.0713734\n",
      "[5700]\ttrain's rmse: 0.071703\teval's rmse: 0.071365\n",
      "[5800]\ttrain's rmse: 0.0716931\teval's rmse: 0.071358\n",
      "[5900]\ttrain's rmse: 0.0716867\teval's rmse: 0.0713505\n",
      "[6000]\ttrain's rmse: 0.0716696\teval's rmse: 0.0713337\n",
      "[6100]\ttrain's rmse: 0.0716659\teval's rmse: 0.0713314\n",
      "[6200]\ttrain's rmse: 0.0716628\teval's rmse: 0.0713285\n",
      "[6300]\ttrain's rmse: 0.0716513\teval's rmse: 0.0713183\n",
      "[6400]\ttrain's rmse: 0.0716372\teval's rmse: 0.0713055\n",
      "[6500]\ttrain's rmse: 0.0716329\teval's rmse: 0.0713018\n",
      "[6600]\ttrain's rmse: 0.0716239\teval's rmse: 0.0712939\n",
      "[6700]\ttrain's rmse: 0.071619\teval's rmse: 0.0712908\n",
      "[6800]\ttrain's rmse: 0.0716135\teval's rmse: 0.0712848\n",
      "[6900]\ttrain's rmse: 0.0716069\teval's rmse: 0.0712792\n",
      "[7000]\ttrain's rmse: 0.0715989\teval's rmse: 0.0712731\n",
      "[7100]\ttrain's rmse: 0.0715905\teval's rmse: 0.071265\n",
      "[7200]\ttrain's rmse: 0.0715848\teval's rmse: 0.0712584\n",
      "[7300]\ttrain's rmse: 0.0715832\teval's rmse: 0.0712577\n",
      "[7400]\ttrain's rmse: 0.0715751\teval's rmse: 0.0712502\n",
      "[7500]\ttrain's rmse: 0.0715672\teval's rmse: 0.0712426\n",
      "[7600]\ttrain's rmse: 0.0715577\teval's rmse: 0.0712339\n",
      "[7700]\ttrain's rmse: 0.071542\teval's rmse: 0.0712195\n",
      "[7800]\ttrain's rmse: 0.0715257\teval's rmse: 0.0712044\n",
      "[7900]\ttrain's rmse: 0.0715158\teval's rmse: 0.0711946\n",
      "[8000]\ttrain's rmse: 0.0715075\teval's rmse: 0.0711877\n",
      "[8100]\ttrain's rmse: 0.0714916\teval's rmse: 0.0711707\n",
      "[8200]\ttrain's rmse: 0.0714893\teval's rmse: 0.07117\n",
      "[8300]\ttrain's rmse: 0.0714795\teval's rmse: 0.0711601\n",
      "[8400]\ttrain's rmse: 0.0714775\teval's rmse: 0.0711595\n",
      "[8500]\ttrain's rmse: 0.0714686\teval's rmse: 0.0711523\n",
      "[8600]\ttrain's rmse: 0.0714602\teval's rmse: 0.0711447\n",
      "[8700]\ttrain's rmse: 0.071453\teval's rmse: 0.0711377\n",
      "[8800]\ttrain's rmse: 0.0714472\teval's rmse: 0.0711332\n",
      "[8900]\ttrain's rmse: 0.0714423\teval's rmse: 0.0711286\n",
      "[9000]\ttrain's rmse: 0.0714358\teval's rmse: 0.0711216\n",
      "[9100]\ttrain's rmse: 0.0714342\teval's rmse: 0.0711204\n",
      "[9200]\ttrain's rmse: 0.0714304\teval's rmse: 0.0711181\n",
      "[9300]\ttrain's rmse: 0.0714235\teval's rmse: 0.0711113\n",
      "[9400]\ttrain's rmse: 0.0714217\teval's rmse: 0.0711102\n",
      "[9500]\ttrain's rmse: 0.0714183\teval's rmse: 0.0711067\n",
      "[9600]\ttrain's rmse: 0.0714153\teval's rmse: 0.0711048\n",
      "[9700]\ttrain's rmse: 0.071408\teval's rmse: 0.071099\n",
      "[9800]\ttrain's rmse: 0.0714004\teval's rmse: 0.0710912\n",
      "[9900]\ttrain's rmse: 0.0713966\teval's rmse: 0.0710878\n",
      "[10000]\ttrain's rmse: 0.0713939\teval's rmse: 0.0710848\n",
      "[10100]\ttrain's rmse: 0.0713924\teval's rmse: 0.0710846\n",
      "[10200]\ttrain's rmse: 0.0713872\teval's rmse: 0.07108\n",
      "[10300]\ttrain's rmse: 0.0713816\teval's rmse: 0.0710754\n",
      "[10400]\ttrain's rmse: 0.071377\teval's rmse: 0.0710716\n",
      "[10500]\ttrain's rmse: 0.0713712\teval's rmse: 0.0710648\n",
      "[10600]\ttrain's rmse: 0.0713699\teval's rmse: 0.0710631\n",
      "[10700]\ttrain's rmse: 0.071363\teval's rmse: 0.0710551\n",
      "[10800]\ttrain's rmse: 0.0713564\teval's rmse: 0.0710492\n",
      "[10900]\ttrain's rmse: 0.0713515\teval's rmse: 0.0710446\n",
      "[11000]\ttrain's rmse: 0.0713398\teval's rmse: 0.0710334\n",
      "[11100]\ttrain's rmse: 0.0713335\teval's rmse: 0.071029\n",
      "[11200]\ttrain's rmse: 0.0713278\teval's rmse: 0.0710234\n",
      "[11300]\ttrain's rmse: 0.0713248\teval's rmse: 0.0710207\n",
      "[11400]\ttrain's rmse: 0.0713229\teval's rmse: 0.071019\n",
      "[11500]\ttrain's rmse: 0.0713168\teval's rmse: 0.0710126\n",
      "[11600]\ttrain's rmse: 0.0713093\teval's rmse: 0.0710047\n",
      "[11700]\ttrain's rmse: 0.0713065\teval's rmse: 0.0710026\n",
      "[11800]\ttrain's rmse: 0.0713026\teval's rmse: 0.0709992\n",
      "[11900]\ttrain's rmse: 0.0712965\teval's rmse: 0.0709928\n",
      "[12000]\ttrain's rmse: 0.071295\teval's rmse: 0.0709926\n",
      "[12100]\ttrain's rmse: 0.0712928\teval's rmse: 0.0709899\n",
      "[12200]\ttrain's rmse: 0.071287\teval's rmse: 0.0709833\n",
      "[12300]\ttrain's rmse: 0.0712847\teval's rmse: 0.0709818\n",
      "[12400]\ttrain's rmse: 0.0712824\teval's rmse: 0.0709798\n",
      "[12500]\ttrain's rmse: 0.0712746\teval's rmse: 0.0709727\n",
      "[12600]\ttrain's rmse: 0.0712738\teval's rmse: 0.0709715\n",
      "[12700]\ttrain's rmse: 0.0712724\teval's rmse: 0.0709707\n",
      "[12800]\ttrain's rmse: 0.0712692\teval's rmse: 0.0709687\n",
      "[12900]\ttrain's rmse: 0.0712669\teval's rmse: 0.0709659\n",
      "[13000]\ttrain's rmse: 0.0712616\teval's rmse: 0.0709619\n",
      "[13100]\ttrain's rmse: 0.0712549\teval's rmse: 0.0709569\n",
      "[13200]\ttrain's rmse: 0.0712523\teval's rmse: 0.0709552\n",
      "[13300]\ttrain's rmse: 0.0712511\teval's rmse: 0.0709543\n",
      "[13400]\ttrain's rmse: 0.0712495\teval's rmse: 0.0709528\n",
      "[13500]\ttrain's rmse: 0.0712429\teval's rmse: 0.070947\n",
      "[13600]\ttrain's rmse: 0.0712372\teval's rmse: 0.0709415\n",
      "[13700]\ttrain's rmse: 0.0712346\teval's rmse: 0.0709381\n",
      "[13800]\ttrain's rmse: 0.0712305\teval's rmse: 0.0709348\n",
      "[13900]\ttrain's rmse: 0.071228\teval's rmse: 0.0709325\n",
      "[14000]\ttrain's rmse: 0.071224\teval's rmse: 0.0709279\n",
      "[14100]\ttrain's rmse: 0.0712194\teval's rmse: 0.0709237\n",
      "[14200]\ttrain's rmse: 0.071218\teval's rmse: 0.070922\n",
      "[14300]\ttrain's rmse: 0.0712136\teval's rmse: 0.0709182\n",
      "[14400]\ttrain's rmse: 0.0712095\teval's rmse: 0.0709151\n",
      "[14500]\ttrain's rmse: 0.0712082\teval's rmse: 0.0709147\n",
      "[14600]\ttrain's rmse: 0.0712045\teval's rmse: 0.0709114\n",
      "[14700]\ttrain's rmse: 0.0711992\teval's rmse: 0.0709046\n",
      "[14800]\ttrain's rmse: 0.0711934\teval's rmse: 0.0708986\n",
      "[14900]\ttrain's rmse: 0.0711878\teval's rmse: 0.0708933\n",
      "[15000]\ttrain's rmse: 0.0711865\teval's rmse: 0.0708918\n",
      "[15100]\ttrain's rmse: 0.0711841\teval's rmse: 0.0708896\n",
      "[15200]\ttrain's rmse: 0.071183\teval's rmse: 0.070889\n",
      "[15300]\ttrain's rmse: 0.0711809\teval's rmse: 0.0708881\n",
      "[15400]\ttrain's rmse: 0.0711781\teval's rmse: 0.0708862\n",
      "[15500]\ttrain's rmse: 0.0711774\teval's rmse: 0.0708853\n",
      "[15600]\ttrain's rmse: 0.0711726\teval's rmse: 0.0708804\n",
      "[15700]\ttrain's rmse: 0.0711709\teval's rmse: 0.0708797\n",
      "[15800]\ttrain's rmse: 0.0711695\teval's rmse: 0.0708787\n",
      "[15900]\ttrain's rmse: 0.0711638\teval's rmse: 0.0708731\n",
      "[16000]\ttrain's rmse: 0.0711631\teval's rmse: 0.0708727\n",
      "[16100]\ttrain's rmse: 0.0711614\teval's rmse: 0.0708703\n",
      "[16200]\ttrain's rmse: 0.0711587\teval's rmse: 0.070869\n",
      "[16300]\ttrain's rmse: 0.0711547\teval's rmse: 0.0708656\n",
      "[16400]\ttrain's rmse: 0.0711511\teval's rmse: 0.0708622\n",
      "[16500]\ttrain's rmse: 0.071148\teval's rmse: 0.0708591\n",
      "[16600]\ttrain's rmse: 0.071146\teval's rmse: 0.0708576\n",
      "[16700]\ttrain's rmse: 0.0711426\teval's rmse: 0.0708534\n",
      "[16800]\ttrain's rmse: 0.0711396\teval's rmse: 0.0708516\n",
      "[16900]\ttrain's rmse: 0.0711331\teval's rmse: 0.0708464\n",
      "[17000]\ttrain's rmse: 0.0711309\teval's rmse: 0.070844\n",
      "[17100]\ttrain's rmse: 0.0711297\teval's rmse: 0.0708427\n",
      "[17200]\ttrain's rmse: 0.0711272\teval's rmse: 0.0708405\n",
      "[17300]\ttrain's rmse: 0.0711255\teval's rmse: 0.0708392\n",
      "[17400]\ttrain's rmse: 0.0711232\teval's rmse: 0.0708359\n",
      "[17500]\ttrain's rmse: 0.0711165\teval's rmse: 0.0708291\n",
      "[17600]\ttrain's rmse: 0.0711144\teval's rmse: 0.0708271\n",
      "[17700]\ttrain's rmse: 0.071113\teval's rmse: 0.070826\n",
      "[17800]\ttrain's rmse: 0.0711106\teval's rmse: 0.0708241\n",
      "[17900]\ttrain's rmse: 0.0711087\teval's rmse: 0.0708226\n",
      "[18000]\ttrain's rmse: 0.0711043\teval's rmse: 0.0708184\n",
      "[18100]\ttrain's rmse: 0.0711035\teval's rmse: 0.0708188\n",
      "[18200]\ttrain's rmse: 0.0711004\teval's rmse: 0.0708162\n",
      "[18300]\ttrain's rmse: 0.0710994\teval's rmse: 0.070815\n",
      "[18400]\ttrain's rmse: 0.0710965\teval's rmse: 0.0708138\n",
      "[18500]\ttrain's rmse: 0.0710931\teval's rmse: 0.0708102\n",
      "[18600]\ttrain's rmse: 0.0710907\teval's rmse: 0.0708075\n",
      "[18700]\ttrain's rmse: 0.0710859\teval's rmse: 0.0708031\n",
      "[18800]\ttrain's rmse: 0.0710839\teval's rmse: 0.0708006\n",
      "[18900]\ttrain's rmse: 0.0710822\teval's rmse: 0.0707988\n",
      "[19000]\ttrain's rmse: 0.07108\teval's rmse: 0.0707977\n",
      "[19100]\ttrain's rmse: 0.0710787\teval's rmse: 0.0707959\n",
      "[19200]\ttrain's rmse: 0.0710751\teval's rmse: 0.0707923\n",
      "[19300]\ttrain's rmse: 0.0710734\teval's rmse: 0.0707918\n",
      "[19400]\ttrain's rmse: 0.0710723\teval's rmse: 0.0707912\n",
      "[19500]\ttrain's rmse: 0.0710709\teval's rmse: 0.0707902\n",
      "[19600]\ttrain's rmse: 0.0710702\teval's rmse: 0.0707899\n",
      "[19700]\ttrain's rmse: 0.0710667\teval's rmse: 0.0707866\n",
      "[19800]\ttrain's rmse: 0.0710644\teval's rmse: 0.0707844\n",
      "[19900]\ttrain's rmse: 0.0710634\teval's rmse: 0.0707839\n",
      "[20000]\ttrain's rmse: 0.0710619\teval's rmse: 0.0707828\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[19925]\ttrain's rmse: 0.0710621\teval's rmse: 0.0707823\n",
      "Training time: 00:04:04\n",
      "Train rmse: 0.07106\n",
      "Valid rmse: 0.07078\n",
      "[I 2025-07-20 20:58:16,336] Trial 5 finished with value: 0.07078233613905366 and parameters: {'max_depth': 6, 'num_leaves': 419, 'min_child_samples': 6053, 'min_split_gain': 0.004374364439939076, 'feature_fraction': 0.3183057352267168, 'bagging_fraction': 0.7985530730333811, 'bagging_freq': 1, 'lambda_l1': 2.857080075040721, 'lambda_l2': 0.0003570095960030948}. Best is trial 0 with value: 0.060481305339152816.\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttrain's rmse: 0.0944057\teval's rmse: 0.0937666\n",
      "[200]\ttrain's rmse: 0.0805338\teval's rmse: 0.0799852\n",
      "[300]\ttrain's rmse: 0.0760001\teval's rmse: 0.0754861\n",
      "[400]\ttrain's rmse: 0.0744224\teval's rmse: 0.0739248\n",
      "[500]\ttrain's rmse: 0.0739011\teval's rmse: 0.0734141\n",
      "[600]\ttrain's rmse: 0.0737423\teval's rmse: 0.0732547\n",
      "[700]\ttrain's rmse: 0.0736635\teval's rmse: 0.0731853\n",
      "[800]\ttrain's rmse: 0.0736312\teval's rmse: 0.0731553\n",
      "[900]\ttrain's rmse: 0.0735996\teval's rmse: 0.0731261\n",
      "[1000]\ttrain's rmse: 0.0735753\teval's rmse: 0.0731024\n",
      "[1100]\ttrain's rmse: 0.0735748\teval's rmse: 0.0731009\n",
      "[1200]\ttrain's rmse: 0.0735748\teval's rmse: 0.0731009\n",
      "[1300]\ttrain's rmse: 0.0735748\teval's rmse: 0.0731009\n",
      "[1400]\ttrain's rmse: 0.0735748\teval's rmse: 0.0731009\n",
      "[1500]\ttrain's rmse: 0.0735748\teval's rmse: 0.0731009\n",
      "Early stopping, best iteration is:\n",
      "[1013]\ttrain's rmse: 0.0735748\teval's rmse: 0.0731009\n",
      "Training time: 00:00:32\n",
      "Train rmse: 0.07357\n",
      "Valid rmse: 0.07310\n",
      "[I 2025-07-20 20:58:49,178] Trial 6 finished with value: 0.07310089747574755 and parameters: {'max_depth': 8, 'num_leaves': 462, 'min_child_samples': 5560, 'min_split_gain': 0.01906609163818845, 'feature_fraction': 0.32772816832882906, 'bagging_fraction': 0.9408753883293675, 'bagging_freq': 12, 'lambda_l1': 4.33504539277513, 'lambda_l2': 2.3386439256208704}. Best is trial 0 with value: 0.060481305339152816.\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttrain's rmse: 0.0935154\teval's rmse: 0.0929077\n",
      "[200]\ttrain's rmse: 0.0798834\teval's rmse: 0.0793715\n",
      "[300]\ttrain's rmse: 0.0755484\teval's rmse: 0.0750793\n",
      "[400]\ttrain's rmse: 0.0738149\teval's rmse: 0.0733623\n",
      "[500]\ttrain's rmse: 0.0729835\teval's rmse: 0.0725604\n",
      "[600]\ttrain's rmse: 0.0724814\teval's rmse: 0.0720924\n",
      "[700]\ttrain's rmse: 0.0720776\teval's rmse: 0.0717145\n",
      "[800]\ttrain's rmse: 0.0718352\teval's rmse: 0.0714998\n",
      "[900]\ttrain's rmse: 0.0716453\teval's rmse: 0.0713334\n",
      "[1000]\ttrain's rmse: 0.0714285\teval's rmse: 0.0711392\n",
      "[1100]\ttrain's rmse: 0.0712402\teval's rmse: 0.0709757\n",
      "[1200]\ttrain's rmse: 0.0710538\teval's rmse: 0.0708081\n",
      "[1300]\ttrain's rmse: 0.0709456\teval's rmse: 0.0707145\n",
      "[1400]\ttrain's rmse: 0.0708374\teval's rmse: 0.0706244\n",
      "[1500]\ttrain's rmse: 0.0707441\teval's rmse: 0.0705504\n",
      "[1600]\ttrain's rmse: 0.0706616\teval's rmse: 0.0704845\n",
      "[1700]\ttrain's rmse: 0.070564\teval's rmse: 0.0704024\n",
      "[1800]\ttrain's rmse: 0.0704788\teval's rmse: 0.0703349\n",
      "[1900]\ttrain's rmse: 0.0704026\teval's rmse: 0.0702752\n",
      "[2000]\ttrain's rmse: 0.0703399\teval's rmse: 0.0702272\n",
      "[2100]\ttrain's rmse: 0.0702819\teval's rmse: 0.0701814\n",
      "[2200]\ttrain's rmse: 0.0702423\teval's rmse: 0.0701555\n",
      "[2300]\ttrain's rmse: 0.0702076\teval's rmse: 0.0701354\n",
      "[2400]\ttrain's rmse: 0.0701711\teval's rmse: 0.0701092\n",
      "[2500]\ttrain's rmse: 0.0701343\teval's rmse: 0.0700817\n",
      "[2600]\ttrain's rmse: 0.0701006\teval's rmse: 0.0700678\n",
      "[2700]\ttrain's rmse: 0.0700753\teval's rmse: 0.0700517\n",
      "[2800]\ttrain's rmse: 0.0700459\teval's rmse: 0.0700331\n",
      "[2900]\ttrain's rmse: 0.0700248\teval's rmse: 0.0700208\n",
      "[3000]\ttrain's rmse: 0.0699972\teval's rmse: 0.070006\n",
      "[3100]\ttrain's rmse: 0.0699786\teval's rmse: 0.0699928\n",
      "[3200]\ttrain's rmse: 0.0699575\teval's rmse: 0.0699808\n",
      "[3300]\ttrain's rmse: 0.0699386\teval's rmse: 0.0699713\n",
      "[3400]\ttrain's rmse: 0.0699175\teval's rmse: 0.0699638\n",
      "[3500]\ttrain's rmse: 0.0698956\teval's rmse: 0.0699494\n",
      "[3600]\ttrain's rmse: 0.0698763\teval's rmse: 0.0699346\n",
      "[3700]\ttrain's rmse: 0.069857\teval's rmse: 0.0699272\n",
      "[3800]\ttrain's rmse: 0.0698412\teval's rmse: 0.0699191\n",
      "[3900]\ttrain's rmse: 0.0698257\teval's rmse: 0.0699105\n",
      "[4000]\ttrain's rmse: 0.0698112\teval's rmse: 0.0699107\n",
      "[4100]\ttrain's rmse: 0.0697952\teval's rmse: 0.0699018\n",
      "[4200]\ttrain's rmse: 0.0697799\teval's rmse: 0.0698933\n",
      "[4300]\ttrain's rmse: 0.0697668\teval's rmse: 0.0698889\n",
      "[4400]\ttrain's rmse: 0.0697536\teval's rmse: 0.0698913\n",
      "[4500]\ttrain's rmse: 0.0697408\teval's rmse: 0.0698854\n",
      "[4600]\ttrain's rmse: 0.0697288\teval's rmse: 0.0698796\n",
      "[4700]\ttrain's rmse: 0.0697175\teval's rmse: 0.0698757\n",
      "[4800]\ttrain's rmse: 0.0697048\teval's rmse: 0.0698717\n",
      "[4900]\ttrain's rmse: 0.0696935\teval's rmse: 0.069871\n",
      "[5000]\ttrain's rmse: 0.0696797\teval's rmse: 0.0698626\n",
      "[5100]\ttrain's rmse: 0.0696663\teval's rmse: 0.0698536\n",
      "[5200]\ttrain's rmse: 0.0696536\teval's rmse: 0.0698497\n",
      "[5300]\ttrain's rmse: 0.0696421\teval's rmse: 0.0698491\n",
      "[5400]\ttrain's rmse: 0.069634\teval's rmse: 0.0698445\n",
      "[5500]\ttrain's rmse: 0.0696242\teval's rmse: 0.0698407\n",
      "[5600]\ttrain's rmse: 0.0696152\teval's rmse: 0.0698382\n",
      "[5700]\ttrain's rmse: 0.0696069\teval's rmse: 0.069835\n",
      "[5800]\ttrain's rmse: 0.0695961\teval's rmse: 0.0698298\n",
      "[5900]\ttrain's rmse: 0.0695879\teval's rmse: 0.0698274\n",
      "[6000]\ttrain's rmse: 0.0695792\teval's rmse: 0.0698277\n",
      "[6100]\ttrain's rmse: 0.0695706\teval's rmse: 0.069825\n",
      "[6200]\ttrain's rmse: 0.0695613\teval's rmse: 0.0698256\n",
      "[6300]\ttrain's rmse: 0.0695522\teval's rmse: 0.0698206\n",
      "[6400]\ttrain's rmse: 0.0695436\teval's rmse: 0.0698204\n",
      "[6500]\ttrain's rmse: 0.0695353\teval's rmse: 0.0698181\n",
      "[6600]\ttrain's rmse: 0.0695254\teval's rmse: 0.0698165\n",
      "[6700]\ttrain's rmse: 0.069519\teval's rmse: 0.0698167\n",
      "[6800]\ttrain's rmse: 0.0695108\teval's rmse: 0.0698155\n",
      "[6900]\ttrain's rmse: 0.0695034\teval's rmse: 0.0698141\n",
      "[7000]\ttrain's rmse: 0.0694953\teval's rmse: 0.0698146\n",
      "[7100]\ttrain's rmse: 0.0694885\teval's rmse: 0.0698141\n",
      "[7200]\ttrain's rmse: 0.0694808\teval's rmse: 0.0698111\n",
      "[7300]\ttrain's rmse: 0.0694724\teval's rmse: 0.0698021\n",
      "[7400]\ttrain's rmse: 0.0694636\teval's rmse: 0.0698066\n",
      "[7500]\ttrain's rmse: 0.0694568\teval's rmse: 0.0698041\n",
      "[7600]\ttrain's rmse: 0.0694485\teval's rmse: 0.069807\n",
      "[7700]\ttrain's rmse: 0.0694415\teval's rmse: 0.0698073\n",
      "[7800]\ttrain's rmse: 0.0694364\teval's rmse: 0.0698047\n",
      "Early stopping, best iteration is:\n",
      "[7313]\ttrain's rmse: 0.0694716\teval's rmse: 0.0697993\n",
      "Training time: 00:11:35\n",
      "Train rmse: 0.06947\n",
      "Valid rmse: 0.06980\n",
      "[I 2025-07-20 21:10:25,245] Trial 7 finished with value: 0.0697993014707842 and parameters: {'max_depth': 8, 'num_leaves': 585, 'min_child_samples': 4265, 'min_split_gain': 0.0001499329805509155, 'feature_fraction': 0.3067840933365807, 'bagging_fraction': 0.7475990992289793, 'bagging_freq': 6, 'lambda_l1': 0.0004247116662617141, 'lambda_l2': 0.9384800715909529}. Best is trial 0 with value: 0.060481305339152816.\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttrain's rmse: 0.0686739\teval's rmse: 0.0679704\n",
      "[200]\ttrain's rmse: 0.0647537\teval's rmse: 0.0641316\n",
      "[300]\ttrain's rmse: 0.0637725\teval's rmse: 0.0632107\n",
      "[400]\ttrain's rmse: 0.0633306\teval's rmse: 0.0628136\n",
      "[500]\ttrain's rmse: 0.0629908\teval's rmse: 0.0625124\n",
      "[600]\ttrain's rmse: 0.0626903\teval's rmse: 0.0622382\n",
      "[700]\ttrain's rmse: 0.0624629\teval's rmse: 0.062042\n",
      "[800]\ttrain's rmse: 0.0623035\teval's rmse: 0.0619037\n",
      "[900]\ttrain's rmse: 0.0621433\teval's rmse: 0.0617715\n",
      "[1000]\ttrain's rmse: 0.0620102\teval's rmse: 0.0616617\n",
      "[1100]\ttrain's rmse: 0.061912\teval's rmse: 0.0615943\n",
      "[1200]\ttrain's rmse: 0.0617989\teval's rmse: 0.0615088\n",
      "[1300]\ttrain's rmse: 0.0617067\teval's rmse: 0.0614364\n",
      "[1400]\ttrain's rmse: 0.0616261\teval's rmse: 0.0613778\n",
      "[1500]\ttrain's rmse: 0.0615442\teval's rmse: 0.0613138\n",
      "[1600]\ttrain's rmse: 0.0614775\teval's rmse: 0.0612656\n",
      "[1700]\ttrain's rmse: 0.0614229\teval's rmse: 0.0612291\n",
      "[1800]\ttrain's rmse: 0.0613686\teval's rmse: 0.0611946\n",
      "[1900]\ttrain's rmse: 0.0613062\teval's rmse: 0.061149\n",
      "[2000]\ttrain's rmse: 0.0612531\teval's rmse: 0.0611193\n",
      "[2100]\ttrain's rmse: 0.0612058\teval's rmse: 0.0610885\n",
      "[2200]\ttrain's rmse: 0.0611643\teval's rmse: 0.0610621\n",
      "[2300]\ttrain's rmse: 0.0611248\teval's rmse: 0.0610427\n",
      "[2400]\ttrain's rmse: 0.0610888\teval's rmse: 0.0610226\n",
      "[2500]\ttrain's rmse: 0.0610469\teval's rmse: 0.0609971\n",
      "[2600]\ttrain's rmse: 0.0610139\teval's rmse: 0.0609828\n",
      "[2700]\ttrain's rmse: 0.0609796\teval's rmse: 0.0609571\n",
      "[2800]\ttrain's rmse: 0.0609486\teval's rmse: 0.0609481\n",
      "[2900]\ttrain's rmse: 0.060917\teval's rmse: 0.0609351\n",
      "[3000]\ttrain's rmse: 0.0608796\teval's rmse: 0.0609084\n",
      "[3100]\ttrain's rmse: 0.0608492\teval's rmse: 0.0608932\n",
      "[3200]\ttrain's rmse: 0.0608227\teval's rmse: 0.0608813\n",
      "[3300]\ttrain's rmse: 0.0607938\teval's rmse: 0.0608701\n",
      "[3400]\ttrain's rmse: 0.0607657\teval's rmse: 0.0608576\n",
      "[3500]\ttrain's rmse: 0.0607395\teval's rmse: 0.0608456\n",
      "[3600]\ttrain's rmse: 0.0607151\teval's rmse: 0.0608287\n",
      "[3700]\ttrain's rmse: 0.0606888\teval's rmse: 0.0608215\n",
      "[3800]\ttrain's rmse: 0.0606626\teval's rmse: 0.060809\n",
      "[3900]\ttrain's rmse: 0.0606411\teval's rmse: 0.0607952\n",
      "[4000]\ttrain's rmse: 0.06062\teval's rmse: 0.0607866\n",
      "[4100]\ttrain's rmse: 0.0605926\teval's rmse: 0.0607849\n",
      "[4200]\ttrain's rmse: 0.0605702\teval's rmse: 0.060776\n",
      "[4300]\ttrain's rmse: 0.060546\teval's rmse: 0.060765\n",
      "[4400]\ttrain's rmse: 0.0605274\teval's rmse: 0.0607601\n",
      "[4500]\ttrain's rmse: 0.0605071\teval's rmse: 0.060754\n",
      "[4600]\ttrain's rmse: 0.0604858\teval's rmse: 0.0607407\n",
      "[4700]\ttrain's rmse: 0.0604667\teval's rmse: 0.0607361\n",
      "[4800]\ttrain's rmse: 0.0604488\teval's rmse: 0.0607296\n",
      "[4900]\ttrain's rmse: 0.0604263\teval's rmse: 0.0607195\n",
      "[5000]\ttrain's rmse: 0.0604071\teval's rmse: 0.0607148\n",
      "[5100]\ttrain's rmse: 0.060386\teval's rmse: 0.060705\n",
      "[5200]\ttrain's rmse: 0.0603704\teval's rmse: 0.0607007\n",
      "[5300]\ttrain's rmse: 0.0603548\teval's rmse: 0.0606979\n",
      "[5400]\ttrain's rmse: 0.0603382\teval's rmse: 0.0606917\n",
      "[5500]\ttrain's rmse: 0.0603217\teval's rmse: 0.0606852\n",
      "[5600]\ttrain's rmse: 0.060307\teval's rmse: 0.0606805\n",
      "[5700]\ttrain's rmse: 0.060292\teval's rmse: 0.060676\n",
      "[5800]\ttrain's rmse: 0.0602775\teval's rmse: 0.060676\n",
      "[5900]\ttrain's rmse: 0.0602603\teval's rmse: 0.0606678\n",
      "[6000]\ttrain's rmse: 0.0602462\teval's rmse: 0.0606666\n",
      "[6100]\ttrain's rmse: 0.0602319\teval's rmse: 0.0606609\n",
      "[6200]\ttrain's rmse: 0.0602179\teval's rmse: 0.0606596\n",
      "[6300]\ttrain's rmse: 0.0602018\teval's rmse: 0.0606497\n",
      "[6400]\ttrain's rmse: 0.0601885\teval's rmse: 0.0606523\n",
      "[6500]\ttrain's rmse: 0.0601729\teval's rmse: 0.0606485\n",
      "[6600]\ttrain's rmse: 0.0601553\teval's rmse: 0.0606384\n",
      "[6700]\ttrain's rmse: 0.0601417\teval's rmse: 0.0606362\n",
      "[6800]\ttrain's rmse: 0.0601261\teval's rmse: 0.0606311\n",
      "[6900]\ttrain's rmse: 0.0601147\teval's rmse: 0.0606294\n",
      "[7000]\ttrain's rmse: 0.0601012\teval's rmse: 0.0606281\n",
      "[7100]\ttrain's rmse: 0.0600877\teval's rmse: 0.0606249\n",
      "[7200]\ttrain's rmse: 0.0600754\teval's rmse: 0.0606244\n",
      "[7300]\ttrain's rmse: 0.0600625\teval's rmse: 0.0606249\n",
      "[7400]\ttrain's rmse: 0.0600494\teval's rmse: 0.0606216\n",
      "[7500]\ttrain's rmse: 0.0600356\teval's rmse: 0.0606202\n",
      "[7600]\ttrain's rmse: 0.0600232\teval's rmse: 0.0606182\n",
      "[7700]\ttrain's rmse: 0.0600104\teval's rmse: 0.060611\n",
      "[7800]\ttrain's rmse: 0.0599994\teval's rmse: 0.0606089\n",
      "[7900]\ttrain's rmse: 0.0599875\teval's rmse: 0.0606076\n",
      "[8000]\ttrain's rmse: 0.0599754\teval's rmse: 0.0606091\n",
      "[8100]\ttrain's rmse: 0.0599646\teval's rmse: 0.0606128\n",
      "[8200]\ttrain's rmse: 0.0599543\teval's rmse: 0.0606124\n",
      "[8300]\ttrain's rmse: 0.0599418\teval's rmse: 0.0606068\n",
      "[8400]\ttrain's rmse: 0.0599306\teval's rmse: 0.0606072\n",
      "[8500]\ttrain's rmse: 0.0599173\teval's rmse: 0.0606034\n",
      "[8600]\ttrain's rmse: 0.0599064\teval's rmse: 0.0606028\n",
      "[8700]\ttrain's rmse: 0.0598954\teval's rmse: 0.0605935\n",
      "[8800]\ttrain's rmse: 0.0598856\teval's rmse: 0.0605934\n",
      "[8900]\ttrain's rmse: 0.0598757\teval's rmse: 0.0605911\n",
      "[9000]\ttrain's rmse: 0.0598657\teval's rmse: 0.0605892\n",
      "[9100]\ttrain's rmse: 0.0598509\teval's rmse: 0.0605865\n",
      "[9200]\ttrain's rmse: 0.0598397\teval's rmse: 0.0605813\n",
      "[9300]\ttrain's rmse: 0.05983\teval's rmse: 0.0605911\n",
      "[9400]\ttrain's rmse: 0.0598207\teval's rmse: 0.0605852\n",
      "[9500]\ttrain's rmse: 0.0598105\teval's rmse: 0.0605825\n",
      "[9600]\ttrain's rmse: 0.0598\teval's rmse: 0.0605724\n",
      "[9700]\ttrain's rmse: 0.0597867\teval's rmse: 0.0605711\n",
      "[9800]\ttrain's rmse: 0.059777\teval's rmse: 0.0605709\n",
      "[9900]\ttrain's rmse: 0.0597672\teval's rmse: 0.0605681\n",
      "[10000]\ttrain's rmse: 0.0597567\teval's rmse: 0.0605692\n",
      "[10100]\ttrain's rmse: 0.0597491\teval's rmse: 0.060566\n",
      "[10200]\ttrain's rmse: 0.0597396\teval's rmse: 0.0605672\n",
      "[10300]\ttrain's rmse: 0.059729\teval's rmse: 0.0605671\n",
      "[10400]\ttrain's rmse: 0.0597212\teval's rmse: 0.0605692\n",
      "[10500]\ttrain's rmse: 0.0597103\teval's rmse: 0.0605592\n",
      "[10600]\ttrain's rmse: 0.0597022\teval's rmse: 0.0605656\n",
      "[10700]\ttrain's rmse: 0.0596931\teval's rmse: 0.0605599\n",
      "[10800]\ttrain's rmse: 0.0596854\teval's rmse: 0.0605597\n",
      "[10900]\ttrain's rmse: 0.0596762\teval's rmse: 0.06056\n",
      "[11000]\ttrain's rmse: 0.0596672\teval's rmse: 0.0605641\n",
      "[11100]\ttrain's rmse: 0.0596595\teval's rmse: 0.0605626\n",
      "[11200]\ttrain's rmse: 0.0596506\teval's rmse: 0.0605589\n",
      "[11300]\ttrain's rmse: 0.0596425\teval's rmse: 0.0605569\n",
      "[11400]\ttrain's rmse: 0.0596349\teval's rmse: 0.0605577\n",
      "[11500]\ttrain's rmse: 0.0596267\teval's rmse: 0.0605566\n",
      "[11600]\ttrain's rmse: 0.0596176\teval's rmse: 0.0605601\n",
      "[11700]\ttrain's rmse: 0.0596091\teval's rmse: 0.0605542\n",
      "[11800]\ttrain's rmse: 0.0596004\teval's rmse: 0.0605519\n",
      "[11900]\ttrain's rmse: 0.0595931\teval's rmse: 0.0605549\n",
      "[12000]\ttrain's rmse: 0.059584\teval's rmse: 0.0605517\n",
      "[12100]\ttrain's rmse: 0.059575\teval's rmse: 0.0605566\n",
      "[12200]\ttrain's rmse: 0.0595667\teval's rmse: 0.0605525\n",
      "[12300]\ttrain's rmse: 0.0595574\teval's rmse: 0.0605522\n",
      "Early stopping, best iteration is:\n",
      "[11832]\ttrain's rmse: 0.0595991\teval's rmse: 0.06055\n",
      "Training time: 00:12:18\n",
      "Train rmse: 0.05960\n",
      "Valid rmse: 0.06055\n",
      "[I 2025-07-20 21:22:43,615] Trial 8 finished with value: 0.06054997502402709 and parameters: {'max_depth': 7, 'num_leaves': 456, 'min_child_samples': 5628, 'min_split_gain': 7.007213496896404e-05, 'feature_fraction': 0.42032954711310594, 'bagging_fraction': 0.6723651931039313, 'bagging_freq': 15, 'lambda_l1': 0.43000015861626045, 'lambda_l2': 0.00015570196345516618}. Best is trial 0 with value: 0.060481305339152816.\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[100]\ttrain's rmse: 0.0696655\teval's rmse: 0.0688509\n",
      "[200]\ttrain's rmse: 0.0675988\teval's rmse: 0.0668114\n",
      "[300]\ttrain's rmse: 0.067517\teval's rmse: 0.0667228\n",
      "[400]\ttrain's rmse: 0.067517\teval's rmse: 0.0667228\n",
      "[500]\ttrain's rmse: 0.067517\teval's rmse: 0.0667228\n",
      "[600]\ttrain's rmse: 0.067517\teval's rmse: 0.0667228\n",
      "[700]\ttrain's rmse: 0.067517\teval's rmse: 0.0667228\n",
      "Early stopping, best iteration is:\n",
      "[263]\ttrain's rmse: 0.067517\teval's rmse: 0.0667228\n",
      "Training time: 00:00:09\n",
      "Train rmse: 0.06752\n",
      "Valid rmse: 0.06672\n",
      "[I 2025-07-20 21:22:53,089] Trial 9 finished with value: 0.06672277922211874 and parameters: {'max_depth': 5, 'num_leaves': 563, 'min_child_samples': 6121, 'min_split_gain': 0.2366154006460316, 'feature_fraction': 0.41569055200289184, 'bagging_fraction': 0.6722133955202271, 'bagging_freq': 6, 'lambda_l1': 4.956947932799954e-05, 'lambda_l2': 1.5087613675681661}. Best is trial 0 with value: 0.060481305339152816.\n"
     ]
    }
   ],
   "source": [
    "# tr_df1のtuning\n",
    "importlib.reload(cv)\n",
    "importlib.reload(op)\n",
    "\n",
    "params = {\n",
    "    \"max_depth\": 5,\n",
    "    \"num_leaves\": 523,\n",
    "    \"min_child_samples\": 5056,\n",
    "    \"min_split_gain\": 9.275294835907687e-05,\n",
    "    \"feature_fraction\": 0.43593953046851464,\n",
    "    \"bagging_fraction\": 0.8924361138693251,\n",
    "    \"bagging_freq\": 10,\n",
    "    \"lambda_l1\": 1.6934155410667961,\n",
    "    \"lambda_l2\": 0.6637926838138378\n",
    "}\n",
    "\n",
    "objective = op.create_objective(\n",
    "    tr_df1,\n",
    "    early_stopping_rounds=500,\n",
    "    n_jobs=25\n",
    ")\n",
    "\n",
    "random_sampler = optuna.samplers.RandomSampler(seed=42)\n",
    "\n",
    "study = op.run_optuna_search(\n",
    "    objective,\n",
    "    n_trials=10,\n",
    "    n_jobs=1,\n",
    "    study_name=\"lgbm_v1\",\n",
    "    storage=url,\n",
    "    sampler=random_sampler,\n",
    "    initial_params=params\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.12",
   "language": "python",
   "name": "rapids-23.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
