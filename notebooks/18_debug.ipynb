{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0310ea3f-39d4-4522-bfd2-303c8c76fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import src.models.mlp.mlp_cv_trainer as cv\n",
    "import src.utils.optuna_visualizer as opv\n",
    "import src.utils.telegram as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0483e9a2-ecc5-4078-a62a-31ab26efcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "env_path = Path.cwd().parent / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "url = os.environ.get(\"OPTUNA_STORAGE_URL\")\n",
    "\n",
    "l1_tr_df1 = pd.read_parquet(\"../artifacts/features/l1/l1_tr_df1.parquet\").astype(\"float32\")\n",
    "l1_test_df1 = pd.read_parquet(\"../artifacts/features/l1/l1_test_df1.parquet\").astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e836cd54-1420-42d6-92fc-db92689d9d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train RMSE = 0.16513, Val RMSE = 0.16484\n",
      "Epoch 2: Train RMSE = 0.11175, Val RMSE = 0.11142\n",
      "Epoch 3: Train RMSE = 0.07598, Val RMSE = 0.07563\n",
      "Epoch 4: Train RMSE = 0.06225, Val RMSE = 0.06183\n",
      "Epoch 5: Train RMSE = 0.11754, Val RMSE = 0.11724\n",
      "Epoch 6: Train RMSE = 0.06891, Val RMSE = 0.06864\n",
      "Epoch 7: Train RMSE = 0.07291, Val RMSE = 0.07263\n",
      "Epoch 8: Train RMSE = 0.08675, Val RMSE = 0.08662\n",
      "Epoch 9: Train RMSE = 0.07062, Val RMSE = 0.07039\n",
      "Epoch 10: Train RMSE = 0.07246, Val RMSE = 0.07222\n",
      "Epoch 11: Train RMSE = 0.06890, Val RMSE = 0.06868\n",
      "Epoch 12: Train RMSE = 0.07237, Val RMSE = 0.07218\n",
      "Epoch 13: Train RMSE = 0.07324, Val RMSE = 0.07298\n",
      "Epoch 14: Train RMSE = 0.06177, Val RMSE = 0.06153\n",
      "Epoch 15: Train RMSE = 0.07290, Val RMSE = 0.07262\n",
      "Epoch 16: Train RMSE = 0.06796, Val RMSE = 0.06767\n",
      "Epoch 17: Train RMSE = 0.06874, Val RMSE = 0.06850\n",
      "Epoch 18: Train RMSE = 0.06687, Val RMSE = 0.06663\n",
      "Epoch 19: Train RMSE = 0.06762, Val RMSE = 0.06739\n",
      "Epoch 20: Train RMSE = 0.07032, Val RMSE = 0.07009\n",
      "Epoch 21: Train RMSE = 0.06358, Val RMSE = 0.06335\n",
      "Epoch 22: Train RMSE = 0.06692, Val RMSE = 0.06674\n",
      "Epoch 23: Train RMSE = 0.07667, Val RMSE = 0.07651\n",
      "Epoch 24: Train RMSE = 0.05981, Val RMSE = 0.05955\n",
      "Epoch 25: Train RMSE = 0.06085, Val RMSE = 0.06053\n",
      "Epoch 26: Train RMSE = 0.07264, Val RMSE = 0.07245\n",
      "Epoch 27: Train RMSE = 0.06183, Val RMSE = 0.06162\n",
      "Epoch 28: Train RMSE = 0.07085, Val RMSE = 0.07060\n",
      "Epoch 29: Train RMSE = 0.05964, Val RMSE = 0.05939\n",
      "Epoch 30: Train RMSE = 0.06624, Val RMSE = 0.06603\n",
      "Epoch 31: Train RMSE = 0.05974, Val RMSE = 0.05951\n",
      "Epoch 32: Train RMSE = 0.07102, Val RMSE = 0.07079\n",
      "Epoch 33: Train RMSE = 0.06497, Val RMSE = 0.06475\n",
      "Epoch 34: Train RMSE = 0.06332, Val RMSE = 0.06308\n",
      "Epoch 35: Train RMSE = 0.06083, Val RMSE = 0.06059\n",
      "Epoch 36: Train RMSE = 0.06022, Val RMSE = 0.05996\n",
      "Epoch 37: Train RMSE = 0.06198, Val RMSE = 0.06173\n",
      "Epoch 38: Train RMSE = 0.06019, Val RMSE = 0.05993\n",
      "Epoch 39: Train RMSE = 0.06621, Val RMSE = 0.06599\n",
      "Epoch 40: Train RMSE = 0.05980, Val RMSE = 0.05955\n",
      "Epoch 41: Train RMSE = 0.06043, Val RMSE = 0.06019\n",
      "Epoch 42: Train RMSE = 0.06317, Val RMSE = 0.06292\n",
      "Epoch 43: Train RMSE = 0.06119, Val RMSE = 0.06093\n",
      "Epoch 44: Train RMSE = 0.06218, Val RMSE = 0.06196\n",
      "Epoch 45: Train RMSE = 0.06546, Val RMSE = 0.06522\n",
      "Epoch 46: Train RMSE = 0.06452, Val RMSE = 0.06428\n",
      "Epoch 47: Train RMSE = 0.05968, Val RMSE = 0.05943\n",
      "Epoch 48: Train RMSE = 0.05941, Val RMSE = 0.05915\n",
      "Epoch 49: Train RMSE = 0.06171, Val RMSE = 0.06148\n",
      "Epoch 50: Train RMSE = 0.06282, Val RMSE = 0.06258\n",
      "Epoch 51: Train RMSE = 0.06176, Val RMSE = 0.06153\n",
      "Epoch 52: Train RMSE = 0.06015, Val RMSE = 0.05990\n",
      "Epoch 53: Train RMSE = 0.06620, Val RMSE = 0.06598\n",
      "Epoch 54: Train RMSE = 0.06194, Val RMSE = 0.06170\n",
      "Epoch 55: Train RMSE = 0.06117, Val RMSE = 0.06093\n",
      "Epoch 56: Train RMSE = 0.06835, Val RMSE = 0.06812\n",
      "Epoch 57: Train RMSE = 0.06022, Val RMSE = 0.05998\n",
      "Epoch 58: Train RMSE = 0.06240, Val RMSE = 0.06217\n",
      "Epoch 59: Train RMSE = 0.06346, Val RMSE = 0.06323\n",
      "Epoch 60: Train RMSE = 0.06439, Val RMSE = 0.06416\n",
      "Epoch 61: Train RMSE = 0.06148, Val RMSE = 0.06123\n",
      "Epoch 62: Train RMSE = 0.06053, Val RMSE = 0.06028\n",
      "Epoch 63: Train RMSE = 0.06208, Val RMSE = 0.06185\n",
      "Epoch 64: Train RMSE = 0.06014, Val RMSE = 0.05990\n",
      "Epoch 65: Train RMSE = 0.06641, Val RMSE = 0.06619\n",
      "Epoch 66: Train RMSE = 0.06576, Val RMSE = 0.06554\n",
      "Epoch 67: Train RMSE = 0.07420, Val RMSE = 0.07399\n",
      "Epoch 68: Train RMSE = 0.06179, Val RMSE = 0.06152\n",
      "Epoch 69: Train RMSE = 0.06510, Val RMSE = 0.06487\n",
      "Early stopping at epoch 69\n",
      "New best model saved at epoch 69, RMSE: 0.06487\n",
      "Training time: 00:15:56\n",
      "Best RMSE: 0.05915\n",
      "✅ Message sent successfully.\n"
     ]
    }
   ],
   "source": [
    "# oofとの差を検証\n",
    "importlib.reload(cv)\n",
    "params = {\n",
    "    \"batch_size\": 224,\n",
    "    \"lr\": 0.0033251860643844526,\n",
    "    \"dropout_rate\": 0.09,\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"hidden_dim1\": 320,\n",
    "    \"hidden_dim2\": 224\n",
    "}\n",
    "trainer = cv.MLPCVTrainer(**params)\n",
    "\n",
    "trainer.fit_one_fold(l1_tr_df1)\n",
    "te.send_telegram_message(\"MLP Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6893556-5352-41ac-bcda-8d6dda9509d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1: train_rmse = 0.09190, val_rmse = 0.09176\n",
      "Epoch 10: train_rmse = 0.10410, val_rmse = 0.10384\n",
      "Epoch 20: train_rmse = 0.06006, val_rmse = 0.05982\n",
      "Epoch 30: train_rmse = 0.06028, val_rmse = 0.06004\n",
      "Epoch 40: train_rmse = 0.05934, val_rmse = 0.05909\n",
      "Epoch 50: train_rmse = 0.06002, val_rmse = 0.05977\n",
      "Epoch 60: train_rmse = 0.05980, val_rmse = 0.05955\n",
      "Epoch 70: train_rmse = 0.05963, val_rmse = 0.05938\n",
      "Epoch 80: train_rmse = 0.06320, val_rmse = 0.06297\n",
      "Epoch 90: train_rmse = 0.05961, val_rmse = 0.05937\n",
      "Early stopping at epoch 96\n",
      "Best RMSE: 0.05899\n",
      "Training time: 00:09:55\n",
      "\n",
      "Fold 2\n",
      "Epoch 1: train_rmse = 0.08279, val_rmse = 0.08348\n",
      "Epoch 10: train_rmse = 0.06354, val_rmse = 0.06399\n",
      "Epoch 20: train_rmse = 0.06522, val_rmse = 0.06618\n",
      "Epoch 30: train_rmse = 0.06459, val_rmse = 0.06517\n",
      "Epoch 40: train_rmse = 0.06270, val_rmse = 0.06346\n",
      "Epoch 50: train_rmse = 0.05943, val_rmse = 0.06007\n",
      "Epoch 60: train_rmse = 0.05924, val_rmse = 0.05996\n",
      "Epoch 70: train_rmse = 0.06094, val_rmse = 0.06182\n",
      "Epoch 80: train_rmse = 0.05935, val_rmse = 0.06002\n",
      "Epoch 90: train_rmse = 0.06167, val_rmse = 0.06256\n",
      "Epoch 100: train_rmse = 0.06162, val_rmse = 0.06251\n",
      "Best RMSE: 0.05988\n",
      "Training time: 00:10:34\n",
      "\n",
      "Fold 3\n",
      "Epoch 1: train_rmse = 0.13861, val_rmse = 0.13847\n",
      "Epoch 10: train_rmse = 0.07222, val_rmse = 0.07194\n",
      "Epoch 20: train_rmse = 0.06191, val_rmse = 0.06167\n",
      "Epoch 30: train_rmse = 0.06339, val_rmse = 0.06308\n",
      "Epoch 40: train_rmse = 0.06077, val_rmse = 0.06045\n",
      "Epoch 50: train_rmse = 0.05955, val_rmse = 0.05926\n",
      "Epoch 60: train_rmse = 0.05996, val_rmse = 0.05965\n",
      "Early stopping at epoch 67\n",
      "Best RMSE: 0.05900\n",
      "Training time: 00:06:59\n",
      "\n",
      "Fold 4\n",
      "Epoch 1: train_rmse = 0.07226, val_rmse = 0.07217\n",
      "Epoch 10: train_rmse = 0.07141, val_rmse = 0.07148\n",
      "Epoch 20: train_rmse = 0.06034, val_rmse = 0.06059\n",
      "Epoch 30: train_rmse = 0.05957, val_rmse = 0.05995\n",
      "Early stopping at epoch 33\n",
      "Best RMSE: 0.05954\n",
      "Training time: 00:03:31\n",
      "\n",
      "Fold 5\n",
      "Epoch 1: train_rmse = 0.13039, val_rmse = 0.13002\n",
      "Epoch 10: train_rmse = 0.09620, val_rmse = 0.09614\n",
      "Epoch 20: train_rmse = 0.06164, val_rmse = 0.06144\n",
      "Epoch 30: train_rmse = 0.06239, val_rmse = 0.06219\n",
      "Epoch 40: train_rmse = 0.06281, val_rmse = 0.06261\n",
      "Epoch 50: train_rmse = 0.06130, val_rmse = 0.06108\n",
      "Epoch 60: train_rmse = 0.06054, val_rmse = 0.06038\n",
      "Epoch 70: train_rmse = 0.06015, val_rmse = 0.05999\n",
      "Early stopping at epoch 70\n",
      "Best RMSE: 0.05905\n",
      "Training time: 00:07:22\n",
      "\n",
      "=== CV 結果 ===\n",
      "Fold scores: [0.05898943849328631, 0.059881995466771275, 0.059000398262622454, 0.05954284503735971, 0.059053761047653905]\n",
      "Mean: 0.05929, Std: 0.00036\n",
      "OOF score: 0.06085\n",
      "Avg best epoch: 55.6\n",
      "Best epochs: \n",
      "[75, 96, 46, 12, 49]\n"
     ]
    }
   ],
   "source": [
    "# oof, test_predsの作成\n",
    "importlib.reload(cv)\n",
    "params = {\n",
    "    \"batch_size\": 512,\n",
    "    \"lr\": 0.006912279003734971,\n",
    "    \"dropout_rate\": 0.09,\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"hidden_dim1\": 256,\n",
    "    \"hidden_dim2\": 192\n",
    "}\n",
    "trainer = cv.MLPCVTrainer(**params)\n",
    "\n",
    "oof, test_preds = trainer.fit(l1_tr_df1, l1_test_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07785f4d-7fcb-4673-ba72-41e0bf095f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1: train_rmse = 0.24391, val_rmse = 0.24374\n",
      "Epoch 10: train_rmse = 0.09302, val_rmse = 0.09283\n",
      "Epoch 20: train_rmse = 0.06325, val_rmse = 0.06298\n",
      "Epoch 30: train_rmse = 0.05974, val_rmse = 0.05945\n",
      "Epoch 40: train_rmse = 0.06233, val_rmse = 0.06206\n",
      "Epoch 50: train_rmse = 0.06040, val_rmse = 0.06015\n",
      "Epoch 60: train_rmse = 0.05933, val_rmse = 0.05905\n",
      "Epoch 70: train_rmse = 0.06031, val_rmse = 0.06004\n",
      "Epoch 80: train_rmse = 0.06018, val_rmse = 0.05992\n",
      "Early stopping at epoch 81\n",
      "Best RMSE: 0.05905\n",
      "Training time: 00:08:18\n",
      "\n",
      "Fold 2\n",
      "Epoch 1: train_rmse = 0.08221, val_rmse = 0.08278\n",
      "Epoch 10: train_rmse = 0.06794, val_rmse = 0.06866\n",
      "Epoch 20: train_rmse = 0.06712, val_rmse = 0.06793\n",
      "Epoch 30: train_rmse = 0.06270, val_rmse = 0.06359\n",
      "Epoch 40: train_rmse = 0.06061, val_rmse = 0.06156\n",
      "Epoch 50: train_rmse = 0.05990, val_rmse = 0.06061\n",
      "Epoch 60: train_rmse = 0.06094, val_rmse = 0.06190\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      2\u001b[39m params = {\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m736\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.005365450324352026\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhidden_dim2\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m128\u001b[39m\n\u001b[32m      9\u001b[39m }\n\u001b[32m     10\u001b[39m trainer = cv.MLPCVTrainer(**params)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m oof, test_preds = trainer.fit(l1_tr_df1, l1_test_df1)\n\u001b[32m     13\u001b[39m np.save(\u001b[33m\"\u001b[39m\u001b[33m../artifacts/preds/l1/oof_single_7.npy\u001b[39m\u001b[33m\"\u001b[39m, oof)\n\u001b[32m     14\u001b[39m np.save(\u001b[33m\"\u001b[39m\u001b[33m../artifacts/preds/l1/test_single_7.npy\u001b[39m\u001b[33m\"\u001b[39m, test_preds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/hanse/kaggle/calorie/src/models/mlp/mlp_cv_trainer.py:211\u001b[39m, in \u001b[36mfit\u001b[39m\u001b[34m(self, tr_df, test_df)\u001b[39m\n\u001b[32m    208\u001b[39m     optimizer.step()\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m model.eval()\n\u001b[32m    212\u001b[39m preds = []\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    629\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m data = \u001b[38;5;28mself\u001b[39m._next_data()\n\u001b[32m    632\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[32m    634\u001b[39m         \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[32m    635\u001b[39m         \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    674\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    676\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    677\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     53\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.collate_fn(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:277\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    217\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    218\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    219\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:144\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    141\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map=collate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:144\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    141\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map=collate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:121\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    124\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:174\u001b[39m, in \u001b[36mcollate_tensor_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    172\u001b[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001b[32m    173\u001b[39m     out = elem.new(storage).resize_(\u001b[38;5;28mlen\u001b[39m(batch), *\u001b[38;5;28mlist\u001b[39m(elem.size()))\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack(batch, \u001b[32m0\u001b[39m, out=out)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# oof, test_predsの作成\n",
    "params = {\n",
    "    \"batch_size\": 736,\n",
    "    \"lr\": 0.005365450324352026,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"hidden_dim1\": 256,\n",
    "    \"hidden_dim2\": 128\n",
    "}\n",
    "trainer = cv.MLPCVTrainer(**params)\n",
    "\n",
    "oof, test_preds = trainer.fit(l1_tr_df1, l1_test_df1)\n",
    "np.save(\"../artifacts/preds/l1/oof_single_7.npy\", oof)\n",
    "np.save(\"../artifacts/preds/l1/test_single_7.npy\", test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75568bc5-2e58-4c2f-a5ac-c65fe236d898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# oof, test_predsの作成\n",
    "params = {\n",
    "    \"batch_size\": 320,\n",
    "    \"lr\": 0.007158401724195687,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"hidden_dim1\": 256,\n",
    "    \"hidden_dim2\": 128\n",
    "}\n",
    "trainer = cv.MLPCVTrainer(**params)\n",
    "\n",
    "oof, test_preds = trainer.fit(l1_tr_df1, l1_test_df1)\n",
    "np.save(\"../artifacts/preds/l1/oof_single_8.npy\", oof)\n",
    "np.save(\"../artifacts/preds/l1/test_single_8.npy\", test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1acf5-a556-4e37-9d61-14a1106bb993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# oof, test_predsの作成\n",
    "params = {\n",
    "    \"batch_size\": 1088,\n",
    "    \"lr\": 0.00836670348003045,\n",
    "    \"dropout_rate\": 0.07,\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"hidden_dim1\": 416,\n",
    "    \"hidden_dim2\": 352\n",
    "}\n",
    "trainer = cv.MLPCVTrainer(**params)\n",
    "\n",
    "oof, test_preds = trainer.fit(l1_tr_df2, l1_test_df2)\n",
    "np.save(\"../artifacts/preds/l1/oof_single_24.npy\", oof)\n",
    "np.save(\"../artifacts/preds/l1/test_single_24.npy\", test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd98803-1d92-4626-a878-f35f39a5d7f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# oof, test_predsの作成\n",
    "params = {\n",
    "    \"batch_size\": 896,\n",
    "    \"lr\": 0.007677555887250604,\n",
    "    \"dropout_rate\": 0.05,\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"hidden_dim1\": 384,\n",
    "    \"hidden_dim2\": 352\n",
    "}\n",
    "trainer = cv.MLPCVTrainer(**params)\n",
    "\n",
    "oof, test_preds = trainer.fit(l1_tr_df2, l1_test_df2)\n",
    "np.save(\"../artifacts/preds/l1/oof_single_25.npy\", oof)\n",
    "np.save(\"../artifacts/preds/l1/test_single_25.npy\", test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711ef97-9374-480f-9106-c9ba543d9b3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# oof, test_predsの作成\n",
    "params = {\n",
    "    \"batch_size\": 992,\n",
    "    \"lr\": 0.0025298207248849675,\n",
    "    \"dropout_rate\": 0.0,\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"hidden_dim1\": 448,\n",
    "    \"hidden_dim2\": 384\n",
    "}\n",
    "trainer = cv.MLPCVTrainer(**params)\n",
    "\n",
    "oof, test_preds = trainer.fit(l1_tr_df2, l1_test_df2)\n",
    "np.save(\"../artifacts/preds/l1/oof_single_26.npy\", oof)\n",
    "np.save(\"../artifacts/preds/l1/test_single_26.npy\", test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb56e58-5e8f-45e9-8bcb-8753c31e6b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# oof, test_predsの作成\n",
    "params = {\n",
    "    \"batch_size\": 1152,\n",
    "    \"lr\": 0.008396872216648935,\n",
    "    \"dropout_rate\": 0.07,\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"hidden_dim1\": 288,\n",
    "    \"hidden_dim2\": 224\n",
    "}\n",
    "trainer = cv.MLPCVTrainer(**params)\n",
    "\n",
    "oof, test_preds = trainer.fit(l1_tr_df2, l1_test_df2)\n",
    "np.save(\"../artifacts/preds/l1/oof_single_27.npy\", oof)\n",
    "np.save(\"../artifacts/preds/l1/test_single_27.npy\", test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7a11a-3ba4-4046-813b-26956e30708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils.telegram as te\n",
    "te.send_telegram_message(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d97357-c0d4-41b8-9b3f-aad3d6c1952f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1: train_rmse = 0.13481, val_rmse = 0.13444\n",
      "Epoch 10: train_rmse = 0.07696, val_rmse = 0.07693\n",
      "Epoch 20: train_rmse = 0.07350, val_rmse = 0.07379\n",
      "Epoch 30: train_rmse = 0.06232, val_rmse = 0.06299\n",
      "Epoch 40: train_rmse = 0.06075, val_rmse = 0.06142\n",
      "Epoch 50: train_rmse = 0.05987, val_rmse = 0.06070\n",
      "Epoch 60: train_rmse = 0.05921, val_rmse = 0.06006\n",
      "Epoch 70: train_rmse = 0.05940, val_rmse = 0.06026\n",
      "Early stopping at epoch 78\n",
      "Best RMSE: 0.05992\n",
      "Training time: 00:06:19\n",
      "\n",
      "Fold 2\n",
      "Epoch 1: train_rmse = 0.13684, val_rmse = 0.13832\n",
      "Epoch 10: train_rmse = 0.10156, val_rmse = 0.10222\n",
      "Epoch 20: train_rmse = 0.06270, val_rmse = 0.06378\n",
      "Epoch 30: train_rmse = 0.06169, val_rmse = 0.06285\n",
      "Epoch 40: train_rmse = 0.06138, val_rmse = 0.06265\n",
      "Epoch 50: train_rmse = 0.05902, val_rmse = 0.06045\n",
      "Epoch 60: train_rmse = 0.05904, val_rmse = 0.06043\n",
      "Epoch 70: train_rmse = 0.05952, val_rmse = 0.06104\n",
      "Epoch 80: train_rmse = 0.05900, val_rmse = 0.06048\n",
      "Early stopping at epoch 86\n",
      "Best RMSE: 0.06030\n",
      "Training time: 00:06:59\n",
      "\n",
      "Fold 3\n",
      "Epoch 1: train_rmse = 0.08816, val_rmse = 0.08892\n",
      "Epoch 10: train_rmse = 0.12758, val_rmse = 0.12792\n",
      "Epoch 20: train_rmse = 0.06869, val_rmse = 0.06923\n",
      "Epoch 30: train_rmse = 0.05971, val_rmse = 0.06055\n",
      "Epoch 40: train_rmse = 0.06115, val_rmse = 0.06200\n",
      "Epoch 50: train_rmse = 0.05971, val_rmse = 0.06060\n",
      "Epoch 60: train_rmse = 0.05956, val_rmse = 0.06047\n",
      "Epoch 70: train_rmse = 0.05971, val_rmse = 0.06063\n",
      "Early stopping at epoch 73\n",
      "Best RMSE: 0.06026\n",
      "Training time: 00:05:57\n",
      "\n",
      "Fold 4\n",
      "Epoch 1: train_rmse = 0.10420, val_rmse = 0.10402\n",
      "Epoch 10: train_rmse = 0.11951, val_rmse = 0.11980\n",
      "Epoch 20: train_rmse = 0.06442, val_rmse = 0.06510\n",
      "Epoch 30: train_rmse = 0.05956, val_rmse = 0.06039\n",
      "Epoch 40: train_rmse = 0.06021, val_rmse = 0.06109\n",
      "Epoch 50: train_rmse = 0.06035, val_rmse = 0.06118\n",
      "Early stopping at epoch 51\n",
      "Best RMSE: 0.06039\n",
      "Training time: 00:04:15\n",
      "\n",
      "Fold 5\n",
      "Epoch 1: train_rmse = 0.10651, val_rmse = 0.10582\n",
      "Epoch 10: train_rmse = 0.06732, val_rmse = 0.06697\n",
      "Epoch 20: train_rmse = 0.08545, val_rmse = 0.08532\n",
      "Epoch 30: train_rmse = 0.06038, val_rmse = 0.06008\n",
      "Epoch 40: train_rmse = 0.06058, val_rmse = 0.06045\n",
      "Epoch 50: train_rmse = 0.05950, val_rmse = 0.05941\n",
      "Epoch 60: train_rmse = 0.06088, val_rmse = 0.06077\n",
      "Epoch 70: train_rmse = 0.06055, val_rmse = 0.06044\n",
      "Epoch 80: train_rmse = 0.05998, val_rmse = 0.05987\n",
      "Epoch 90: train_rmse = 0.05988, val_rmse = 0.05981\n",
      "Early stopping at epoch 95\n",
      "Best RMSE: 0.05934\n",
      "Training time: 00:07:36\n",
      "\n",
      "=== CV 結果 ===\n",
      "Fold scores: [0.05991700004009935, 0.06030371120758237, 0.06026388183134351, 0.060392623577752824, 0.05933541747839091]\n",
      "Mean: 0.06004, Std: 0.00039\n",
      "OOF score: 0.06080\n",
      "Avg best epoch: 55.6\n",
      "Best epochs: \n",
      "[57, 65, 52, 30, 74]\n"
     ]
    }
   ],
   "source": [
    "# full train\n",
    "params = {\n",
    "    \"batch_size\": 960,\n",
    "    \"lr\": 0.004888160547569001,\n",
    "    \"dropout_rate\": 0.11,\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"hidden_dim1\": 480,\n",
    "    \"hidden_dim2\": 448,\n",
    "    \"hidden_dim3\": 448\n",
    "}\n",
    "trainer = cv.MLPCVTrainer(**params)\n",
    "\n",
    "test_preds = trainer.fit(tr_df9, test_df9)\n",
    "np.save(\"../artifacts/preds/l1/test_full_9.npy\", test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-2.2.0",
   "language": "python",
   "name": "torch22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
